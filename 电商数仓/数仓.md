## 数仓

### 数据生成模块

#### 数据格式样例

**事件日志数据**

![](https://raw.githubusercontent.com/whn961227/images/master/data/20200805214153.png)

**启动日志数据**

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200805214208.png"  />



### 数据采集模块

#### Hadoop 安装

#### Zookeeper 安装

#### 日志生成

#### 采集日志 Flume

##### 日志采集 Flume 安装

##### 项目经验之 Flume 组件

###### Source

* Taildir Source 相比 Exec Source、Spooling Directory Source 的优势

  **Taildir Source：**断点续传、多目录。Flume 1.6 以前需要自己自定义 Source 记录每次读取文件位置，实现断点续传

   **Exec Source：**可以实时搜集数据，但是在 Flume 不运行或者 Shell 命令出错的情况下，数据将会丢失

  **Spooling Directory Source：**监控目录，不支持断点续传

* batchSize 大小如何设置

  Event 1K 左右，500-1000 合适（默认为 100）

###### Channel

采用 **Kafka Channel**，省去了 Sink，提高了效率

#####  日志采集 Flume 配置

##### Flume 的 ETL 和分类型拦截器

```java
/*
ETL 拦截器：LogETLInterceptor 实现 Interceptor 接口
    ETL：根据 start 标签区分 启动日志（JSON） 和 事件日志（时间戳|JSON）
    校验启动日志：1. 是否为空
                2. 是否符合 JSON 格式 ====> 以 '{' 开头且以 '}' 结尾
    校验事件日志：1. 是否为空
                2. 按 '|' 切割 ====> 判断长度是否为 2
                3. 判断时间戳格式 ====> 是否长度为 13 且 是否每一位都是数字
                4. 判断 JSON 格式 ====> 以 '{' 开头且以 '}' 结尾
    静态内部类 Builder 实现 Interceptor.Builder 接口
    	作用：用来实例化 LogETLInterceptor
*/
/*
日志类型区分拦截器：LogTypeInterceptor 实现 Interceptor 接口
	将启动日志和事件日志区分开来，方便发往 Kafka 的不同 Topic
	向启动日志的 event 的 headers 中添加 "topic","topic_start"
	向事件日志的 event 的 headers 中添加 "topic","topic_event"
	静态内部类 Builder 实现 Interceptor.Builder 接口
    	作用：用来实例化 LogTypeInterceptor
*/
```

> event 包含 header 和 body：body 才是我们实际使用中真正传输的数据，header 传输的数据，我们是不会 Sink 出去的
>
> header 的话，就是在分装 event 对象的时候，我们可以自定义的设置一些 key-value 对，这样做的目的，是为了后续的 **通道多路复用** 做准备的
>
> 在 Source 端产出 event 的时候，通过 header 去区别对待不同的 event，然后在 sink 端的时候，可以通过 header 中的 key 来将不同的 event 放入不同的 Channel 中，紧接着，再通过配置多个 Sink 去不同的 Channel 中取出 event，这样就将 event 分流出去了
>
> 但是这里有一个前提：**不建议通过对 event 的 body 解析来设置 header，因为 flume 就是一个水槽，水槽是不会在中间对水进行加工的，要加工，等水流出去了再加工**

##### 日志采集 Flume 启动停止脚本



#### Kafka 安装

##### Kafka  集群安装

##### Kafka 集群启动停止脚本

##### Kafka Manager 安装

##### Kafka Manager 启动停止脚本

##### 项目经验之 Kafka 压力测试

##### 项目经验之 Kafka 机器数量计算



#### 消费 Kafka 数据 Flume

##### 日志消费 Flume 配置

##### 日志消费 Flume 启动停止脚本