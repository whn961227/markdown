## 网络

### 计算机网络体系结构

#### 五层协议

* **应用层：**为特定应用程序提供数据传输服务，例如 **HTTP**、**DNS** 、**SMTP**、**FTP**、**Telnet**等协议。数据单位为**报文**
* **传输层：**为主机中的**进程**提供通用数据传输服务。运输层包括两层协议：传输控制协议 **TCP**，提供面向连接、可靠的数据传输服务，数据单位为**报文段**；用户数据报协议 **UDP**，提供无连接、尽最大努力的数据传输服务，数据单位为**用户数据报**。TCP 主要提供完整性服务，UDP 主要提供及时性服务
* **网络层：**为**主机**提供数据传输服务。网络层把传输层传递下来的**报文段和用户数据报封装成分组**，包括 **IP**、**ARP** 协议
* **数据链路层：**主机之间可以有很多链路，链路层协议就是为同一链路的主机提供数据传输服务。数据链路层把网络层传下来的**分组封装成帧**，包括 **MAC** 协议
* **物理层：**考虑的是怎样在传输媒体上传输数据比特流，而不是指具体的传输媒体。物理层的作用是尽可能屏蔽传输媒体和通信手段的差异，使数据链路层感觉不到这些差异

#### OSI

* **表示层：**数据压缩、加密以及数据描述，这使得应用程序不必关心在各台主机中数据内部格式不同的问题
* **会话层：**建立及管理会话

#### TCP/IP

将数据链路层和物理层合并为**网络接口层**

TCP/IP 体系结构不严格遵循 OSI 分层概念，应用层可能会直接使用 IP 层或者网络接口层

#### 数据在各层之间的传递过程

在向下的过程中，需要**添加下层协议所需要的首部或者尾部**，而在向上的过程中不断**拆开首部和尾部**

**路由器**只有下面三层协议，因为路由器位于网络核心中，不需要为进程或者应用程序提供服务，因此也就不需要传输层和应用层

### HTTP（超文本传输协议）

#### 基础概念

**URI（Uniform Resource Identifier）：**统一资源标识符，包含 URL 和 URN

**URL（Uniform Resource Locator）：**统一资源定位符，https://www.google.com

**URN（Uniform Resource Name）：**统一资源名称，`urn:isbn:0451450523`

#### 特点

##### 优点

1. **简单**

   HTTP 基本的报文格式是 `header + body`，头部信息是 `key-value`简单文本的形式，易于理解

2. **灵活和易于扩展**

   HTTP 协议里的各类请求方法，URI/URL，状态码，头字段等每个组成要求都没有被固定死，都允许开发人员**自定义和扩充**

   同时 HTTP 由于是工作在应用层，则它**下层可以随意变化**，例如，HTTPS 就是在 HTTP 与 TCP 层之间增加了 SSL/TLS 安全传输层

3. **应用广泛和跨平台**

##### 缺点

1. **无状态**

   好处：因为服务器不会去记忆 HTTP 的状态，所以不需要额外的资源来记录状态信息，这能减轻服务器的负担，能够把更多的 CPU 和内存用来对外提供服务

   坏处：在完成关联性的操作时会非常麻烦，例如 `登录 -> 添加购物车 -> 下单 -> 结算 -> 支付`，这系列操作都要知道用户的身份才行，但服务器不知道这些请求是有关联的，每次都要问一遍身份信息

   解决：用 **Cookie** 技术

   > Cookie 通过在请求和响应报文中写入 Cookie 信息来控制客户端的状态
   >
   > <img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200812112651.png" style="zoom: 80%;" />

2. **明文传输**

3. **不安全**

   * 通信使用明文（不加密），内容可能会被**窃听**
   * 不验证通信方的身份，因此可能遭遇**伪装**
   * 无法证明报文的完整性，可能被**篡改**

   解决：用 HTTPS 的方式解决，通过引入  SSL/TLS 层

#### HTTP/1.1

##### 改进

1. **长连接**

   HTTP/1.0 性能上有一个很大的问题，每发起一个请求，都要新建一次 TCP 连接（三次握手），而且是串行请求，做了无谓的 TCP 连接建立和断开，增加了通信开销

   HTTP/1.1 提出了长连接的通信方式，也叫持久连接。这种方式的好处在于减少了 TCP 连接的重复建立和断开所造成的额外开销，减轻了服务器端的负载

   持久连接的特点是，主要任意一端没有明确提出断开连接，则保持 TCP 连接状态

   <img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200812114303.png"  />

2. **管道网络传输**

   HTTP/1.1 采用了长连接的方式，这使得管道网络传输成为了可能

   即可在**同一个 TCP 连接里面，客户端可以发起多个请求**，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间

   ![](https://raw.githubusercontent.com/whn961227/images/master/data/20200812114549.png)

##### 瓶颈

1. 请求/响应头部**未经压缩**就发送，首部信息越多延迟越大，只能压缩 Body 的部分
2. 发送**冗长的首部**。每次互相发送相同的首部造成的浪费较多
3. 服务器是按请求的顺序响应的，如果服务器响应慢，会导致客户端一直请求不到数据，也就是 **队头阻塞**
4. 没有请求优先级控制
5. 请求只能从客户端开始，服务器只能被动响应

#### HTTP/2

##### 优化

1. **头部压缩**

   HTTP/2 会 **压缩头** 如果同时发出多个请求，他们的头是一样的或是相似的，那么协议会帮你消除重复的部分

   > HPACK 算法：在客户端和服务端同时维护一张头信息表，所有字段都会存入这张表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就提高速度了

2. **二进制格式**

   HTTP/2 不再像 HTTP/1.1 里的纯文本形式的报文，而是全面采用了二进制格式，增加了数据传输的效率

   头信息和数据体都是二进制，并且统称为**帧**：**头信息帧和数据帧**

   <img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200812154830.png" style="zoom: 80%;" />

3. **数据流**

   HTTP/2 的数据包不是按顺序发送的，同一个连接里面连续的数据包，可能属于不同的回应。因此，必须对数据包做标记，指出它属于哪个回应

   **每个请求或回应的所有数据包，称为一个数据流（Stream）**

   每个数据流都标记着一个独一无二的编号，其中规定客户端发出的数据流编号为奇数，服务器发出的数据流编号为偶数

   客户端还可以指定**数据流的优先级**，优先级高的请求，服务器会先响应该请求

   <img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200812155222.png" style="zoom:67%;" />

4. **多路复用**

   HTTP/2 可以在**一个连接中并发多个请求或回应，而不用按顺序一一对应**

   移除了 HTTP/1.1 中的串行请求，不需要排队等待，也就不会出现 **队头阻塞** 的问题，**降低了延迟，大幅度提高了连接的利用率**

   <img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200812155514.png" style="zoom:67%;" />

5. **服务器推送**

   HTTP/2 在一定程度上改善了传统的 **请求-应答** 工作模式，服务端不再是被动的响应，也可以主动向客户端发送消息

##### 缺陷

HTTP/2 主要的问题在于：多个 HTTP 请求在复用一个 TCP 连接，下层的 TCP 协议是不知道有多少个 HTTP 请求的。所以一旦发生丢包现象，就会触发 TCP 的重传机制，这样在一个 TCP 连接中的**所有 HTTP 请求都必须等待这个丢了的包被重传回来**

* HTTP/1.1 中的管道传输中如果有一个请求阻塞了，那么队列后请求也统统被阻塞
* HTTP/2 多请求复用一个 TCP 连接，一旦发生丢包，就会阻塞住所有的 HTTP 请求

#### HTTP/3

这都是基于 TCP 传输层的问题，所以 **HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP**

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200812160235.png" style="zoom:67%;" />

UDP 发生是不管顺序，也不管丢包的，所以不会出现 H]TTP/1.1 的 **队头阻塞** 和 HTTP/2 的一个丢包全部重传问题

UDP 是不可靠传输的，但是**基于 UDP 的 QUIC 协议**可以实现类似 TCP 的可靠性传输

* QUIC 有自己的一套机制可以保证可靠性传输。当某个流发生丢包时，只会阻塞该流，**其他流不会受到影响**

* TLS 升级成了 **1.3** 版本，头部压缩算法升级成了 **QPACK**

* HTTPS 要建立一个连接，要花费 6 次交互，先是建立三次握手，然后是 TLS/1.3 的三次握手。 QUIC 直接把以往的 TCP 和 TLS/1.3 的 6 次交互合并成了 3 次，减少了交互次数

  <img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200812160739.png" style="zoom: 80%;" />

#### HTTP 消息结构

##### 请求报文

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200811113929.png" style="zoom: 33%;" />

##### 响应报文

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200811114418.png" style="zoom: 33%;" />

##### 请求方法

###### HTTP 1.0

**GET：**获取资源

**HEAD：**获取报文首部，和 GET 方法类似，但是不返回报文实体主体部分

**POST：**传输实体主体

> **Get 和 Post 的区别：**
>
> Get 方法的含义是请求从服务器获取资源，这个资源可以是静态的文本 、页面、图片、视频等
>
> Post 方法向 URI 指定的资源提交数据，数据就放在报文的 body 里
>
> 安全和幂等：
>
> 『安全』：请求方法不会破坏服务器上的资源
>
> 『幂等』：多次执行相同的操作，结果都是相同的
>
> **GET 方法**是**安全且幂等**的，因为它是只读操作，无论操作多少次，服务器上的数据都是安全的，且每次的结果都是相同的
>
> **POST 方法**是新增或提交数据操作，会修改服务器上的资源，所以是**不安全**的，且多次提交数据会创建多个资源，所以**不是幂等**的

###### HTTP 1.1

**PUT：**上传文件

**PATCH：**对资源进行部分修改

**DELETE：**删除文件

**OPTIONS：**查询支持的方法

**CONNECT：**要求在与代理服务器通信时建立隧道

**TRACE：**追踪路径

##### 状态码

| 状态码 | 类别                             | 含义                       |
| ------ | -------------------------------- | -------------------------- |
| 1XX    | Informartional（信息性状态码）   | 接收的请求正在处理         |
| 2XX    | Success（成功状态码）            | 请求正常处理完毕           |
| 3XX    | Redirection（重定向状态码）      | 需要进行附加操作以完成请求 |
| 4XX    | Client Error（客户端错误状态码） | 服务器无法处理请求         |
| 5XX    | Server Error（服务器错误状态码） | 服务器处理请求出错         |

* 100 Continue：表明到目前为止都很正常，客户端可以继续发送请求或者忽略这个响应
* **200 OK：服务器响应成功，服务器找到了客户端请求的内容 ，并将内容发给了客户端**
* 204 No Content：请求已经成功处理，但是返回的响应报文不包含实体的主体部分。一般在只需要从客户端往服务器发送信息，而不需要返回数据时使用
* 206 Partial Content：表示客户端进行了范围请求，响应报文包含由 Content-Range 指定范围的实体内容
* **301 Moved Permanently：永久性重定向**
* **302 Found：临时性重定向**
* 303 See Other：和 302 有着相同的功能，但是 303 明确要求客户端应该采用 Get 方法获取资源
* **304 Not Modified：**如果请求报文首部包含一些条件，如果不满足条件，则服务器会返回 304 状态码
* 307 Temporary Redirect：临时性重定向，与 302 的含义类似，但是 307 要求浏览器不会把重定向请求的 POST 方法改成 GET 方法
* **400 Bad Request：请求报文中存在语法错误，无法被服务器解析**
* 401 Unauthorized：该状态码表示发送的请求需要有认证信息（BASIC 认证、DIGEST 认证）。如果之前已进行过一次请求，则表示用户认证失败
* **403 Forbidden：请求被拒绝**
* **404 Not Found：服务器上没有该资源，或者说是服务器上没有找到客户端请求的资源**
* **500 Internal Server Error：服务器正在执行请求时发生错误**
* **501 Not Implemented：**表示客户端请求的功能还不支持
* **502 Bad Gateway：**通常是服务器作为网关或代理时返回的错误码，表示服务器自身工作正常，访问后端服务器发生了错误
* 503 Service Unavailable：服务器暂时处于超负载或正在进行停机维护，现在无法处理请求

#### HTTP 工作原理

1. 客户端连接到 Web 服务器
2. 发送 HTTP 请求
3. 服务器接受请求并返回 HTTP 响应
4. 释放 TCP 连接
5. 客户端浏览器解析 HTML 内容



### HTTPS

#### 实现原理

**HTTPS 是让 HTTP 的数据包通过 SSL/TLS 加密后传输**。通过 SSL，HTTPS 具有了加密（**防窃听**）、认证（**防伪装**）和完整性保护（**防篡改**）

**SSL 安全套接层和 TLS 传输层安全协议**

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200812143738.png" style="zoom: 80%;" />

#### 工作流程

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200812132016.png"  />

1. 用户在浏览器**发起 HTTPS 请求**（如 https://www.mogu.com/），默认使用服务器端的 **443 端口**进行连接
2. HTTPS 需要使用一套 **CA 数字证书**，证书内会附带一个**公钥 Pub**，而与之对应的**私钥 Private** 保留在服务器端不公开
3. 服务端收到请求，**返回配置好的包含公钥 Pub 的证书给客户端**
4. 客户端**收到证书**，**校验合法性**，主要包括是否在有效期内，证书的域名与请求的域名是否匹配，上一级证书是否有效（递归判断，直到判断到系统内置或浏览器配置好的根证书），如果不通过，则显示 HTTPS 警告信息，如果通过则继续
5. 客户端生成一个用于**对称加密的随机 key**，并用证书内的**公钥 Pub 进行加密**，发送给服务端
6. 服务端收到随机 Key 的密文，使用与公钥 Pub 配对的**私钥 Private 进行解密**，得到客户端真正想发送的**随机 Key**
7. 服务端使用客户端发送过来的**随机 key 对要传输的 HTTP 数据进行对称加密**，将密文返回给客户端
8. 客户端使用**随机 key 对称解密密文**，得到 HTTP 数据明文
9. 后续 HTTPS 请求**使用之前交换好的随机 key 进行对称加解密**

#### 对称机密和非对称加密

对称加密是指有一个密钥，用它可以对一段明文加密，加密之后也只能用这个密钥来解密得到明文；**速度快但是无法做到安全的密钥交换**

非对称加密有两个密钥，一个是公钥，一个是私钥，一般来说，公钥用来加密，这时密文只能用私钥才能解开；**解决了密钥交换的问题但是速度慢**

> 注意，严格来讲，私钥并不能用来加密，只能用作签名，这是由于密码学中生成公钥私钥时对不同变量的数学要求是不同的，因此公钥私钥抵抗攻击的能力也不同，在实际使用中不可互换

**为什么不采用两次非对称机密**

最主要的原因是**非对称加解密的耗时要远大于对称加解密**，对性能有很大损耗

#### CA 颁发机构

因为**客户端无法确认收到的公钥是不是真的是服务端发来的**，所以引入 CA

服务端在使用 HTTPS 之前，去经过认证的 CA 机构申请颁发一份**数字证书**，数字证书里包含有证书持有者、证书有效期、公钥等信息，服务端将证书发送给客户端，客户端校验证书身份和要访问的网站身份确实一致后再进行后续的加密操作

为了确认证书是否被篡改，需要采用防伪技术，**数字签名**

具体过程：

1. CA 机构拥有自己的一对公钥和私钥
2. CA 机构在颁发证书时对证书明文信息进行哈希
3. 将哈希值用**私钥进行加密**，得到数字签名

**明文数据和数字签名组成证书，传递给客户端**

1. 客户端得到证书，分解成明文部分 Text 和数字签名 Sig1
2. 用 CA 机构的**公钥进行解签**，得到 Sig2（由于 CA 机构是一种公信身份，因此在系统或浏览器中会内置 CA 机构的证书和公钥信息）
3. 用证书里声明的哈希算法对明文 Text 部分进行哈希得到 H
4. 当自己计算得到的哈希值 T 与**解签**后的 Sig2 **相等**，表示证书可信，没有被篡改

> 非对称加密的签名过程是，私钥将一段消息进行加签，然后将签名部分和消息本身一起发送给对方，收到消息后对签名部分利用公钥解签，如果解签出来的内容和消息本身一致，表明消息没有被篡改

#### HTTP 和 HTTPS 的区别

1. **HTTP** 是超文本传输协议，信息是**明文传输**，存在**安全风险**的问题。HTTPS 则解决 HTTP 不安全的缺陷，在 TCP 和 HTTP 网络层之间加入了 **SSL/TLS** 安全协议，使得报文能够**加密传输**
2. HTTP 连接建立相对简单，TCP **三次握手**之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 **SSL/TLS 的握手过程**，才可进入加密报文传输
3. HTTP 的端口号是 80，HTTPS 的端口号是 443
4. HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的

#### HTTPS 是如何解决 HTTP 的安全问题的（窃听、篡改、冒充）

* 混合加密的方式实现信息的**机密性**
* 摘要算法的方式来实现**完整性**
* 将服务器公钥放入到**数字证书**中，解决了冒充的风险

#### 总结

HTTPS 的出发点是解决 HTTP 明文传输时信息被篡改和监听的问题

* 为了兼顾性能和安全性，使用了非对称加密 + 对称加密的方案
* 为了保证公钥传输中不被篡改，又使用了非对称加密的数字签名功能，借助 CA 机构和系统根证书的机制保证了 HTTPS 证书的公信力

### 传输层

#### TCP 基本认识

##### 格式

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200812163324.png" style="zoom: 67%;" />

**序列号：**在建立连接时由计算机生成的随机数作为初始值，通过 SYN 包传给接收端主机，**每发送一次数据**，就**累加**一次该**数据字节数**的大小。**用来解决网络包乱序问题**

**确认应答号：**指下一次期望收到的数据的序列号，发送端收到这个确认应答后可以认为在这个序号以前的数据都已经被正常接收。**用来解决不丢包的问题**

**控制位：**

* ACK：该位为 1 时，确认应答的字段变为有效，TCP 规定除了最初建立连接时的 SYN 包之外该位必须设置为 1
* RST：该位为 1 时，表示 TCP 连接中出现异常必须强制断开连接
* SYN：该位为 1 时，表示希望建立连接，并在其序列号的字段进行序列号初始值的设定
* FIN：该位为 1 时，表示今后不会再有数据发送，希望断开连接。当通信结束希望断开连接时，通信双方的主机之间就可以互相交换 FIN 位置为 1 的 TCP 段

##### 为什么需要 TCP 协议

IP 层是不可靠的，它不保证网络包的交付，不保证网络包的按序交付，也不保证网络包中的数据的完整性

如果需要保障网路数据包的可靠性，那么就需要由上层（传输层）的 TCP 协议来负责

因为 TCP 是一个工作在**传输层**的可靠数据传输的服务，它能确保接收端接收的网络包是**无损坏，无间隔，非冗余和按序的**

##### 什么是 TCP

TCP 是**面向连接的**，**可靠的**，**基于字节流**的传输层通信协议

* 面向连接：一定是 **一对一** 才能连接，不能像 UDP 协议可以一个主机同时向多个主机发送消息，也就是一对多是无法做到的
* 可靠的：无论网络链路中出现了怎样的链路变化，TCP 都可以保证一个报文一定能够到达接收端
* 字节流：消息是没有边界的，所以无论消息有多大都可以进行传输。并且消息是**有序**的，当前一个消息没有接收到的时候，及时它先收到了后面的字节，也不能给应用层处理，同时对重复的报文会自动丢弃

##### 什么是 TCP 连接

用于保证可靠性和流量控制维护的某些状态信息，这些信息的组合，包括 **Socket**、**序列号**和**窗口大小**称为连接

* Socket：由 IP 地址和端口号组成
* 序列号：用来解决乱序问题
* 窗口大小：用来做流量控制

##### 如何唯一确定一个 TCP 连接

TCP 四元组可以唯一的确定一个连接

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200812171125.png" style="zoom: 50%;" />

源地址和目的地址的字段（32 位）是在 IP 头部中，作用是通过 IP 协议发送报文给对方主机

源端口和目的端口的字段（16  位）是在 TCP 头部中，作用是告诉 TCP 协议应该把报文发给哪个进程

#### UDP 基本认识

UDP 不提供复杂的控制机制，利用 IP 提供面向**无连接**的通信服务

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200812172211.png" style="zoom: 50%;" />

* 目标和源端口：告诉 UDP 协议应该把报文发给哪个进程
* 包长度：该字段保存了 UDP 首部的长度跟数据的长度之和
* 校验和：为了提供可靠的 UDP 首部和数据而设计

#### TCP 和 UDP 的区别

1. **连接**
   * TCP 是面向连接的传输层协议，传输数据前要先建立连接
   * UDP 是不需要连接，即刻传输数据
2. **服务对象**
   * TCP 是一对一的两点服务，即一条连接只有两个端点
   * UDP 支持一对一、一对多、多对多的交互通信
3. **可靠性**
   * TCP 是可靠交付数据的，数据可以无差错、不丢失、不重复、按需到达
   * UDP 是尽最大努力交付，不保证可靠交付数据
4. **拥塞控制、流量控制**
   * TCP 有拥塞控制和流量控制机制，保证数据传输的安全性
   * UDP 没有，即使网络非常拥堵，也不会影响 UDP 的发送速率
5. **首部开销**
   * TCP 首部长度较长，会有一定的开销，首部在没有使用**选项**字段时是 20 个字节，如果使用了选项字段则会变长
   * UDP 首部只有 8 个字节，并且是固定不变的，开销较小

#### TCP 和 UDP 应用场景

由于 TCP 是面向连接，能保证数据的可靠性交付，因此经常用于：

* FTP 文件传输
* HTTP/HTTPS

由于 UDP 面向无连接，它可以随时发送数据，再加上UDP 本身的处理既简单又高效，因此经常用于：

* 包总量较少的通信，如 DNS，SNMP 等
* 视频、音频等多媒体通信
* 广播通信

#### 为什么 UDP 头部没有 **首部长度** 字段，TCP 却有

TCP 有可变长的**选项**字段，而 UDP 头部长度是**不会变化**的，无需多一个字段去记录 UDP 的头部长度

#### 为什么 UDP 头部有 **包长度** 字段，TCP 却没有

TCP 计算负载数据长度：
$$
TCP数据的长度 = IP总长度 - IP首部长度 - TCP首部长度
$$
**因为为了网络设备硬件设计和处理方便，首部长度需要是 4 字节的整数倍**

如果去掉 UDP 包长度字段，那么 UDP 首部长度就不是 4 字节的整数倍了，所以为了补全 UDP 首部长度是 4 字节的整数倍，才补充了包长度字段

#### TCP 建立连接

TCP 是面向连接的协议，所以使用 TCP 前必须先建立连接，而**建立连接是通过三次握手进行的**

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200812205839.png" style="zoom:67%;" />

* 一开始，客户端和服务端都处于 CLOSED 状态，先是服务端主动监听某个端口，处于 LISTEN 状态

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200812210006.png" style="zoom: 67%;" />

* 客户端会随机初始化序号（client_isn），将此序号置于 TCP 首部的**序列号**字段中，同时把 **SYN** 标志位置位 **1**，表示 SYN 报文。接着把第一个 SYN 报文发送给服务端，表示向服务端发起连接，该报文不包含应用层数据，之后客户端处于 **SYN-SENT** 状态

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200812210522.png" style="zoom: 67%;" />

* 服务端收到客户端的 SYN 报文后，首先服务端也随机初始化自己的序号（server_isn），将此序号填入 TCP 首部的**序列号**字段中，其次把 TCP 首部的**确认应答号**字段填入 **client_isn+1**， 接着**把 SYN 和 ACK 标志位置为 1**，最后把该报文发给客户端，该报文也不包含应用层数据，之后服务端处于 **SYN-RCVD** 状态

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200812211111.png" style="zoom:67%;" />

* 客户端收到服务端报文后，还要向服务端回应最后一个应答报文，首先该应答报文 TCP 首部 **ACK 标志位置为 1**，其次**确认应答号**字段填入 **server_isn+1**，最后把报文发送给服务端，这次报文**可以携带客户到服务器的数据**，之后客户端处于 **ESTABLISHED** 状态
* 服务器收到客户端的应答报文后，也进入 **ESTABLISHED** 状态

所以三次握手目的是**保证双方都有发送和接收的能力**

从上面的过程可以发现**第三次握手是可以携带数据的，前两次握手是不可以携带数据的**

#### 如何在 linux 系统中查看 TCP 状态

通过 netstat -napt 命令查看

![](https://raw.githubusercontent.com/whn961227/images/master/data/20200812211544.png)



#### 为什么是三次握手，不是两次、四次

* 可以阻止历史重复连接的初始化（主要原因）
* 可以同步双方的初始序列号
* 可以避免资源浪费

**原因一：避免历史连接**

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200812212150.png" style="zoom: 50%;" />

客户端连续发送多次 SYN 建立连接的报文，在网络拥堵等情况下：

* 一个旧 SYN 报文比最新的 SYN 报文早到达了服务端
* 那么此时服务端就会回一个 **SYN+ACK** 报文给客户端
* 客户端收到后可以根据自身的上下文，判断这是一个历史连接（序列号过期或超时），那么客户端就会发送 **RST** 报文给服务端，表示终止这一次连接

如果是两次握手连接，就不能判断当前连接是否是历史连接，三次握手则可以在客户端（发送方）准备发送第三次报文时，客户端因有足够的上下文来判断当前连接是否是历史连接：

* 如果是历史连接（序列号过期或者超时），则第三次握手发送的报文是 **RST** 报文，以此中断历史连接
* 如果不是历史连接，则第三次发送的报文是 **ACK** 报文，通信双方就会成功建立连接

所以，TCP 使用三次握手建立连接的最主要原因是**防止历史连接初始化**

**原因二：同步双方初始序列号**

TCP 协议的通信双方，都必须维护一个 **序列号**，序列号是可靠传输的一个关键因素，它的作用：

* 接收方可以去除重复的数据
* 接收方可以根据数据包的序列号按序接收
* 可以标识发送出去的数据包中，哪些是已经被对方收到的

可见，序列号在 TCP 连接中占据着非常重要的作用，所以当客户端发送携带 **初始序列号** 的 **SYN** 报文的时候，需要服务端回一个 **ACK** 的应答报文，表示客户端的 **SYN** 报文已被服务端成功接收，那当服务端发送 **初始序列号** 给客户端的时候，依然也要得到客户端的应答回应，**这样一来一回，才能确保双方的初始序列号能被可靠的同步**

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200812213126.png" style="zoom:80%;" />

四次握手其实也能够可靠的同步双方的初始序列号，但由于第二步和第三步可以优化成一步，所以就成了三次握手

而两次握手只保证了一方的初始序列号能被对方成功接收，没办法保证双方的初始序列号都能被确认接收

**原因三：避免资源浪费**

如果只有两次握手，当客户端的 **SYN** 请求连接在网络中阻塞， 客户端没有接收到 **ACK** 报文，就会重新发送 **SYN**，由于没有第三次握手，服务器不清楚客户端是否收到了自己发送的建立连接的 **ACK** 确认信号，所以每收到一个 **SYN** 就只能先主动建立一个连接

如果客户端的 **SYN** 阻塞了，重复发送多次 **SYN** 报文，那么服务器在收到请求后就会**建立多个冗余的无效连接，造成不必要的资源浪费**

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200812213720.png" style="zoom: 50%;" />

**小结**

TCP 建立连接时，通过三次握手**能防止历史连接的建立，能减少双方不必要的资源开销，能帮助双方同步初始序列号**。序列号能够保证数据包不重复、不丢弃和按序传输

不使用 **两次握手** 和 **四次握手** 的原因：

* 两次握手：无法防止历史连接的建立，会造成双方资源的浪费，也无法可靠的同步双方序列号
* 四次握手：三次握手就已经理论上最少可靠建立连接，所以不需要使用更多的通信次数

#### 为什么客户端和服务端的初始序列号 ISN 是不相同的

因为网络中的报文**会延迟，会复制重发，也有可能丢失**，这样会造成的不同连接之间产生相互影响，所以为了避免互相影响，客户端和服务端的初始序列号是随机且不同的

#### 什么是 SYN 攻击，如何避免

**SYN 攻击**

我们都知道 TCP 连接建立是需要三次握手，假设攻击者短时间伪造不同 IP 地址的 `SYN` 报文，服务端每接收到一个 `SYN` 报文，就进入`SYN_RCVD` 状态，但服务端发送出去的 `ACK + SYN` 报文，无法得到未知 IP 主机的 `ACK` 应答，久而久之就会**占满服务端的 SYN 接收队列（未连接队列）**，使得服务器不能为正常用户服务。

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200812215248.png" style="zoom:80%;" />

**避免 SYN 攻击方式一**

通过修改 Linux 内核参数，**控制队列大小**和**当队列满时应做什么处理**

* 当网卡接收数据包的速度大于内核处理的速度时，会有一个队列保存这些数据包。控制该队列的最大值如下参数：

  ```
  net.core.netdev_max_backlog
  ```

* SYN_RCVD 状态连接的最大个数：

  ```
  net.ipv4.tcp_max_syn_backlog
  ```

* 超出处理能力时，对新的 SYN 直接返回 RST，丢弃连接：

  ```
  net.ipv4.tcp_abort_on_overflow
  ```

**避免 SYN 攻击方式二**

我们先来看下Linux 内核的 `SYN` （未完成连接建立）队列与 `Accept` （已完成连接建立）队列是如何工作的？

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200812215617.png" style="zoom: 50%;" />

正常流程：

* 当服务端接收到客户端的 SYN 报文时，会将其加入到内核的「 **SYN 队列**」；
* 接着发送 SYN + ACK 给客户端，等待客户端回应 ACK 报文；
* 服务端接收到 ACK 报文后，从「 SYN 队列」移除放入到「 **Accept 队列**」；
* 应用通过调用 `accept()` socket 接口，从「 Accept 队列」取出的连接。

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200812215741.png" style="zoom:50%;" />

应用程序过慢：

* 如果应用程序过慢时，就会导致「 Accept 队列」被占满

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200812215823.png" style="zoom:50%;" />

受到 SYN 攻击：

* 如果不断受到 SYN 攻击，就会导致「 SYN 队列」被占满。

tcp_syncookies 的方式可以应对 SYN 攻击的方法：

```
net.ipv4.tcp_syncookies = 1
```

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200812215931.png" style="zoom:50%;" />

* 当 「 SYN 队列」满之后，后续服务器收到 SYN 包，不进入「 SYN 队列」；
* 计算出一个 `cookie` 值，再以 SYN + ACK 中的「**序列号**」返回客户端
* 服务端接收到客户端的应答报文时，服务器会**检查这个 ACK 包的合法性**。**如果合法，直接放入到「 Accept 队列」**
* 最后应用通过调用 `accept()` socket 接口，从「 Accept 队列」取出的连接。

#### TCP 断开连接

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200813105340.png" style="zoom: 50%;" />

* 客户端打算关闭连接，此时会发送一个 TCP 首部 **FIN** 标志位被置为 1 的报文，也即 **FIN 报文**，之后客户端进入 **FIN_WAIT_1** 状态
* 服务端收到该报文后，就向客户端发送 **ACK 应答报文**，接着服务器进入 **CLOSE_WAIT** 状态
* 客户端收到服务端的 **ACK 应答报文**后，之后进入 **FIN_WAIT_2** 状态
* 等待服务端处理完数据后，也向客户端发送 **FIN** 报文，之后服务端进入 **LAST_ACK** 状态
* 客户端收到服务端的 **FIN** 报文后，回一个 **ACK 应答报文**，之后进入 **TIME_WAIT** 状态
* 服务器收到了 **ACK 应答报文**后，进入了 **CLOSE** 状态，至此服务器已经完成连接的关闭
* 客户端在经过 **2MSL** 一段时间后，自动进入 **CLOSE** 状态，至此客户端也完成连接的关闭

这里需要注意的是：**主动关闭连接的，才有 TIME_WAIT 状态**

#### 为什么挥手需要四次

回顾四次挥手双方发 FIN 包的过程：

* 关闭连接时，客户端向服务端发送 **FIN** 时，仅仅表示客户端不再发送数据了但是还能接收数据
* 服务器收到客户端的 FIN 报文时，先回一个 **ACK 应答报文**，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 FIN 报文给客户端来表示同意现在关闭连接

从上面过程可知，**服务端通常需要等待完成数据的发送和处理**，所以服务端的 **ACK 和 FIN 一般都会分开发送**，从而比三次握手导致多了一次

#### 为什么 TIME_WAIT 等待的时间是 2MSL

**MSL 是 Maximum Segment Lifetime，报文最大生存时间**，它是任何报文在网络上存在的最大时间，超过这个时间报文将被丢弃。因为 TCP 报文基于是 IP 协议的，而 IP 头中有一个 TTL 字段，是 IP 数据报可以经过的最大路由数，每经过一个处理他的路由器此值就减 1，当此值为 0 则数据报将被丢弃，同时发送 ICMP 报文通知源主机

MSL 与 TTL 的区别：MSL 的单位是**时间**，TTL 的单位是**经过路由跳数**。所以 **MSL 应该要大于等于 TTL 消耗为 0 的时间**，以确保报文已经被自然消亡

TIME_WAIT 等待 2 倍的 MSL，比较合理的解释是：网络中可能存在来自发送方的数据包，当这些发送方的数据包被接收方处理后又会向对方发送响应，所以**一来一回需要等待 2 倍的时间**

比如，如果被动关闭方没有收到断开连接的最后的 ACK 报文，就会触发超时重发 Fin 报文，另一方接收到 FIN 后，会重发 ACK 给被动关闭方， 一来一去正好 2 个 MSL

2MSL 的时间是**从客户端接收到 FIN 后发送 ACK 开始计时的**。如果在 TIME_WAIT 时间内，因为客户端的 ACK 没有传输到服务器，客户端又接收到了服务器重发的 FIN 报文，那么 **2MSL 时间将重新计时**

在 Linux 系统里 2MSL 默认是 60 秒，那么一个 MSL 也就是 30 秒。**Linux 系统停留在 TIME_WAIT 的时间为固定的 60 秒**

其定义在 Linux 内核代码里的名称为 TCP_TIMEWAIT_LEN：

如果要修改 TIME_WAIT 的时间长度，只能修改 Linux 内核代码里 TCP_TIMEWAIT_LEN 的值，并重新编译 Linux 内核

#### 为什么需要 TIME_WAIT 状态

**主动发起关闭连接的一方，才会有 TIME_WAIT 状态**

主要是两个原因：

* 防止具有相同四元组的旧数据包被收到
* 保证被动关闭连接的一方能被正确的关闭，即保证最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭

**原因一：防止旧连接的数据包**

假设 TIME-WAIT 没有等待时间或时间过短，被延迟的数据包抵达后会发生什么呢？

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200813112342.png" style="zoom:50%;" />

* 如上图黄色框框服务端在关闭连接之前发送的 `SEQ = 301` 报文，被网络延迟了
* 这时有相同端口的 TCP 连接被复用后，被延迟的 `SEQ = 301` 抵达了客户端，那么客户端是有可能正常接收这个过期的报文，这就会产生数据错乱等严重的问题

所以，TCP 就设计出了这么一个机制，经过 **2MSL** 这个时间，**足以让两个方向上的数据包都被丢弃，使得原来连接的数据包在网络中都自然消失，再出现的数据包一定都是新连接所产生的**

**原因二：保证连接正确关闭**

TIME_WAIT 作用是**等待足够的时间以确保最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭**

假设 TIME-WAIT 没有等待时间或时间过短，断开连接会造成什么问题呢？

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200813112824.png" style="zoom:50%;" />

* 如上图红色框框客户端四次挥手的最后一个 `ACK` 报文如果在网络中被丢失了，此时如果客户端 `TIME-WAIT` 过短或没有，则就直接进入了 `CLOSE` 状态了，那么服务端则会一直处在 `LASE-ACK` 状态
* 当客户端发起建立连接的 `SYN` 请求报文后，服务端会发送 `RST` 报文给客户端，连接建立的过程就会被终止

如果 TIME-WAIT 等待足够长的情况就会遇到两种情况：

* 服务端正常收到四次挥手的最后一个 `ACK` 报文，则服务端正常关闭连接
* 服务端没有收到四次挥手的最后一个 `ACK` 报文时，则会重发 `FIN` 关闭连接报文并等待新的 `ACK` 报文

所以客户端在 `TIME-WAIT` 状态等待 `2MSL` 时间后，就可以**保证双方的连接都可以正常的关闭**

#### TIME_WAIT 过多有什么危害

如果服务器有处于 TIME_WAIT 状态的 TCP，则说明是由服务器方主动发起的断开请求

过多的 TIME-WAIT 状态主要的危害有两种：

* 内存资源的占用
* 端口资源的占用，一个 TCP 连接至少消耗一个本地端口

第二个危害是会造成严重的后果的，要知道，端口资源也是有限的

**如果服务端 TIME_WAIT 状态过多，占满了所有端口资源，则会导致无法创建新连接**

#### TCP 重传机制

TCP 实现可靠传输的方式之一，是通过**序列号**与**确认应答号**

* 超时重传
* 快速重传
* SACK
* D-SACK

##### 超时重传

在发送数据时，设定一个定时器，当**超过指定的时间**后，没有**收到对方的 ACK 确认应答报文**，就会**重发该数据**

TCP 会在以下两种情况发生超时重传：

* **数据包丢失**
* **确认应答丢失**

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200813173156.png" style="zoom: 50%;" />

> 超时时间应该设置为多少呢？

`RTT`（Round-Trip Time 往返时延）:

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200813174416.png" style="zoom: 67%;" />

RTT 就是**数据从网络一端传送到另一端所需的时间**，也就是包的**往返时间**

超时重传时间是以 RTO（Retransmission Timeout 超时重传时间）表示

假设在重传的情况下，超时时间 `RTO` 「较长或较短」时，会发生什么事情呢？

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200813174810.png" style="zoom: 67%;" />

上图中有两种超时时间不同的情况：

* 当超时时间 **RTO 较大**时，重发就慢，丢了老半天才重发，没有效率，性能差
* 当超时时间 **RTO 较小**时，会导致可能并没有丢就重发，会增加网络阻塞，导致更多的超时，更多的超时导致更多的重发

根据上述的两种情况，我们可以得知，**超时重传时间 RTO 的值应该略大于报文往返  RTT 的值**
<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200813175015.png" style="zoom: 50%;" />

实际上「报文往返 RTT 的值」是经常变化的，因为我们的网络也是时常变化的。也就因为「报文往返 RTT 的值」 是经常波动变化的，所以「超时重传时间 RTO 的值」应该是一个**动态变化的值**

我们来看看 Linux 是如何计算 `RTO` 的呢？

估计往返时间，通常需要采样以下两个：

* 需要 TCP 通过采样 RTT 的时间，然后进行加权平均，算出一个平滑 RTT 的值，而且这个值还是要不断变化的，因为网络状况不断地变化
* 除了采样 RTT，还要采样 RTT 的波动范围，这样就避免如果 RTT 有一个大的波动的话，很难被发现的情况

如果超时重发的数据，再次超时的时候，又需要重传的时候，TCP 的策略是**超时间隔加倍**

也就是**每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍。两次超时，就说明网络环境差，不宜频繁反复发送**

超时触发重传存在的问题是，**超时周期可能相对较长**。那是不是可以有更快的方式呢？

于是就可以用「**快速重传**」机制来解决超时重发的时间等待。

##### 快速重传

CP 还有另外一种**快速重传（Fast Retransmit）机制**，它**不以时间为驱动，而是以数据驱动重传**

![](https://raw.githubusercontent.com/whn961227/images/master/data/20200813175825.png)

在上图，发送方发出了 1，2，3，4，5 份数据：

* 第一份 Seq1 先送到了，于是就 Ack 回 2；
* 结果 Seq2 因为某些原因没收到，Seq3 到达了，于是还是 Ack 回 2；
* 后面的 Seq4 和 Seq5 都到了，但还是 Ack 回 2，因为 Seq2 还是没有收到；
* **发送端收到了三个 Ack = 2 的确认应答报文，知道了 Seq2 还没有收到，就会在定时器过期之前，重传丢失的 Seq2**
* 最后，接收到收到了 Seq2，此时因为 Seq3，Seq4，Seq5 都收到了，于是 Ack 回 6 。

**快速重传的工作方式是当收到三个相同的 Ack 报文时，会在定时器过期之前，重传丢失的报文段**

快速重传机制只解决了一个问题，就是**超时时间的问题**，但是依然面临着另外一个问题，就是**重传的时候，是重传之前一个，还是重传所有的问题**

##### SACK（选择性确认）

这种方式需要在 TCP 头部 **选项** 字段里加一个 **SACK** 的东西，它**可以将缓存的地图发送给发送方**，这样发送方就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以**只重传丢失的数据**

如下图，发送方收到了三次同样的 ACK 确认报文，于是就会触发快速重发机制，通过 `SACK` 信息发现只有 `200~299` 这段数据丢失，则重发时，就只选择了这个 TCP 段进行重复。

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200816143825.png" style="zoom: 67%;" />

##### Duplicate SACK（D-SACK）

主要**使用了 SACK 来告诉发送方有哪些数据被重复接收了**

**作用一：ACK 丢失**

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200816144056.png" style="zoom: 50%;" />

* 「接收方」发给「发送方」的两个 ACK 确认应答都丢失了，所以发送方超时后，重传第一个数据包（3000 ~ 3499）
* 于是**接收方发现数据是重复收到的，于是回了一个 SACK = 3000~3500**，告诉「发送方」 3000~3500 的数据早已被接收了，因为 ACK 都到了 4000 了，已经意味着 4000 之前的所有数据都已收到，所以这个 SACK 就代表着 **D-SACK**
* 这样「发送方」就知道了，数据没有丢，是「接收方」的 ACK 确认报文丢了

**作用二：网络延时**

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200816144547.png" style="zoom: 50%;" />

* 数据包（1000~1499） 被网络延迟了，导致「发送方」没有收到 Ack 1500 的确认报文
* 而后面报文到达的三个相同的 ACK 确认报文，就触发了快速重传机制，但是在重传后，被延迟的数据包（1000~1499）又到了「接收方」
* **所以「接收方」回了一个 SACK=1000~1500，因为 ACK 已经到了 3000，所以这个 SACK 是 D-SACK，表示收到了重复的包**
* 这样发送方就知道快速重传触发的原因不是发出去的包丢了，也不是因为回应的 ACK 包丢了，而是因为网络延迟了

D-SACK 有几个好处：

1. 可以让「发送方」知道，是发出去的包丢了，还是接收方回应的 ACK 包丢了;
2. 可以知道是不是「发送方」的数据包被网络延迟了;
3. 可以知道网络中是不是把「发送方」的数据包给复制了;

#### 滑动窗口

TCP 是每发送一个数据，都要进行一次确认应答。当上一个数据包收到了应答了， 再发送下一个

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200816150940.png" style="zoom:50%;" />

这样的传输方式有一个缺点：**数据包的往返时间越长，通信的效率越低**

为解决这个问题，TCP 引入了**窗口**这个概念。即使在往返时间较长的情况下，它也不会降低网络通信的效率

那么有了窗口，就可以指定窗口大小，窗口大小是指**无需等待确认应答，而可以继续发送数据的最大值**

窗口的实现实际上是操作系统开辟的一个缓存空间，发送方主机在等到确认应答返回之前，必须在缓冲区中保留已发送的数据。如果按期收到确认应答，此时数据就可以从缓存区清除

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200816151333.png" style="zoom:50%;" />

图中的 ACK 600 确认应答报文丢失，也没关系，因为可以通过下一个确认应答进行确认，只要发送方收到了 Ack = 700 确认应答，就意味着 700 之前的所有数据接收方都收到了，这个模式就叫**累计确认**或者**累计应答**

> 窗口大小决定

TCP 头字段里有一个字段叫 Window，也就是窗口大小

**这个字段是接收端告诉发送端自己还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来**

所以，通常窗口的大小是由接收方的决定的

发送方发送的数据大小不能超过接收方的窗口大小，否则接收方就无法正常接收到数据

> 发送方的滑动窗口

下图就是发送方缓存的数据，根据处理的情况分成四个部分，其中深蓝色方框是发送窗口，紫色方框是可用窗口

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200816152327.png" style="zoom: 67%;" />

* #1 是已发送并收到 ACK确认的数据：1~31 字节
* \#2 是已发送但未收到 ACK确认的数据：32~45 字节
* \#3 是未发送但总大小在接收方处理范围内（接收方还有空间）：46~51字节
* \#4 是未发送但总大小超过接收方处理范围（接收方没有空间）：52字节以后

在下图，当发送方把数据「全部」都一下发送出去后，可用窗口的大小就为 0 了，表明可用窗口耗尽，在没收到 ACK 确认之前是无法继续发送数据了

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200816152547.png" style="zoom:67%;" />

在下图，当收到之前发送的数据 `32~36` 字节的 ACK 确认应答后，如果发送窗口的大小没有变化，则**滑动窗口向右边移动 5 个字节，因为有 5 个字节的数据被应答确认**，接下来`52~56` 字节又变成了可用窗口，那么后续也就可以发送 `52~56` 这 5 个字节的数据了

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200816152706.png" style="zoom:67%;" />

> 程序是如何表示发送方的四个部分的呢？

TCP 滑动窗口方案使用**三个指针**来跟踪在四个传输类别中的每一个类别中的字节，其中两个指针是绝对指针（指特定的序列号），一个是相对指针（需要做偏移）

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200816165449.png" style="zoom:67%;" />

* `SND.WND`：表示发送窗口的大小（大小是由接收方指定的）；
* `SND.UNA`：是一个绝对指针，它指向的是已发送但未收到确认的第一个字节的序列号，也就是 #2 的第一个字节
* `SND.NXT`：也是一个绝对指针，它指向未发送但可发送范围的第一个字节的序列号，也就是 #3 的第一个字节
* 指向 #4 的第一个字节是个相对指针，它需要 `SND.UNA` 指针加上 `SND.WND` 大小的偏移量，就可以指向 #4 的第一个字节了

那么可用窗口大小的计算：
$$
可用窗口大小 = SND.UNA + SND.WND - SND.NXT
$$

> 接收方的滑动窗口

* \#1 + #2 是已成功接收并确认的数据（等待应用进程读取）；
* \#3 是未收到数据但可以接收的数据；
* \#4 未收到数据并不可以接收的数据；

![](https://raw.githubusercontent.com/whn961227/images/master/data/20200816165515.png)

 其中三个接收部分，使用两个指针进行划分:

* `RCV.WND`：表示接收窗口的大小，它会通告给发送方
* `RCV.NXT`：是一个指针，它指向期望从发送方发送来的下一个数据字节的序列号，也就是 #3 的第一个字节
* 指向 #4 的第一个字节是个相对指针，它需要 `RCV.NXT` 指针加上 `RCV.WND` 大小的偏移量，就可以指向 #4 的第一个字节了

> 接收窗口和发送窗口的大小是相等的吗

并不是完全相等，接收窗口的大小是**约等于**发送窗口的大小的

因为滑动窗口并不是一成不变的。比如，当接收方的应用进程读取数据的速度非常快的话，这样的话接收窗口可以很快的就空缺出来。新的接收窗口大小，是通过 TCP 报文中的 Windows 字段来告诉发送方。那么这个传输过程是存在时延的，所以接收窗口和发送窗口是越等于的关系

#### 流量控制（少）

发送方不能无脑的发数据给接收方，要考虑接收方处理能力

如果一直无脑的发数据给对方，但对方处理不过来，那么就会导致触发重发机制，从而导致网络流量的无端的浪费

为了解决这种现象发生，**TCP 提供了一种机制可以让发送方根据接收方的实际接收能力控制发送的数据量**，这就是所谓的**流量控制**

#### 拥塞控制

前面的流量控制是避免「发送方」的数据填满「接收方」的缓存，但是并不知道网络的中发生了什么

一般来说，计算机网络都处在一个共享的环境。因此也有可能会因为其他主机之间的通信使得网络拥堵

**在网络出现拥堵时，如果继续发送大量数据包，可能会导致数据包时延、丢失等，这时 TCP 就会重传数据，但是重传就会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，这个情况就会进入恶性循环被不断地放大** 

当网络发送拥塞时，TCP 会自我牺牲，降低发送的数据量

于是有了拥塞控制，控制的目的就是**避免发送方的数据填满整个网络**

为了在发送方调节所要发送数据的量，定义了一个叫做**拥塞窗口**的概念

> 什么是拥塞窗口，和发送窗口有什么关系

拥塞窗口 cwnd 是发送方维护的一个状态变量，它会**根据网络的拥塞程度动态变化的**

我们在前面提到过发送窗口 `swnd` 和接收窗口 `rwnd` 是约等于的关系，那么由于入了拥塞窗口的概念后，此时发送窗口的值是
$$
swnd = min(cwnd, rwnd)
$$
 ，也就是拥塞窗口和接收窗口中的最小值

拥塞窗口 `cwnd` 变化的规则：

* 只要网络中没有出现拥塞，`cwnd` 就会增大；
* 只要网络中没有出现拥塞，`cwnd` 就会增大；

> 如何知道当前网络是否出现了拥塞

只要发送方没有在规定时间内收到 ACK 应答报文，也就是**发生了超时重传**，就会**认为网络出现了拥塞**

> 拥塞控制的控制算法

拥塞控制主要是四个算法：

* 慢启动

* 拥塞避免

* 拥塞发生

* 快速恢复

**慢启动：**

TCP 在刚建立连接完成后，首先是有个慢启动的过程，这个慢启动的意思就是一点一点的提高发送数据包的数量

慢启动的规则：**当发送方每收到一个 ACK，拥塞窗口 cwnd 的大小就会加 1**

这里假定拥塞窗口 `cwnd` 和发送窗口 `swnd` 相等，下面举个栗子：

* 连接建立完成后，一开始初始化 `cwnd = 1`，表示可以传一个 `MSS` 大小的数据
* 当收到一个 ACK 确认应答后，cwnd 增加 1，于是一次能够发送 2 个
* 当收到 2 个的 ACK 确认应答后， cwnd 增加 2，于是就可以比之前多发2 个，所以这一次能够发送 4 个
* 当这 4 个的 ACK 确认到来的时候，每个确认 cwnd 增加 1， 4 个确认 cwnd 增加 4，于是就可以比之前多发 4 个，所以这一次能够发送 8 个

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200816164428.png" style="zoom: 50%;" />

可以看出慢启动算法，发包的个数是**指数性的增长**

> 慢启动涨到什么时候是个头呢

有一个叫**慢启动门限** ssthresh (slow start threshold) 状态变量

* 当 `cwnd < ssthresh` 时，使用慢启动算法
* 当 `cwnd >= ssthresh` 时，就会使用「拥塞避免算法」

**拥塞避免：**

一般来说 `ssthresh` 的大小是 `65535` 字节

那么进入拥塞避免算法后，它的规则是：**每当收到一个 ACK 时，cwnd 增加 1/cwnd**

接上前面的慢启动的栗子，现假定 `ssthresh` 为 `8`：

* 当 8 个 ACK 应答确认到来时，每个确认增加 1/8，8 个 ACK 确认 cwnd 一共增加 1，于是这一次能够发送 9 个 `MSS` 大小的数据，变成了**线性增长**

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200816164858.png" style="zoom: 50%;" />

所以，我们可以发现，拥塞避免算法就是将原本**慢启动算法的指数增长**变成了**线性增长**，还是增长阶段，但是增长速度缓慢了一些

就这么一直增长着后，网络就会慢慢进入了拥塞的状况了，于是就会出现丢包现象，这时就需要对丢失的数据包进行重传

当触发了重传机制 ，就进入了「**拥塞发生**算法」

**拥塞发生：**

当网络出现拥塞，也就是会发生数据包重传，重传机制主要有两种：

* 超时重传
* 快速重传

> 发生超时重传的拥塞发生算法

当发生了「超时重传」，则就会使用拥塞发生算法

这个时候，sshresh 和 cwnd 的值会发生变化：

* `ssthresh` 设为 `cwnd/2`
* `cwnd` 重置为 `1`

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200816165535.png" style="zoom:50%;" />

接着，就重新开始慢启动，慢启动是会突然减少数据流的。这真是一旦「超时重传」，马上回到解放前。但是这种方式太激进了，反应也很强烈，会造成网络卡顿

> 发生快速重传的拥塞发生算法

还有更好的方式，前面我们讲过「快速重传算法」。当接收方发现丢了一个中间包的时候，发送三次前一个包的 ACK，于是发送端就会快速地重传，不必等待超时再重传

TCP 认为这种情况不严重，因为大部分没丢，只丢了一小部分，则 `ssthresh` 和 `cwnd` 变化如下：

* `cwnd = cwnd/2` ，也就是设置为原来的一半
* `ssthresh = cwnd`
* 进入快速恢复算法

**快速恢复：**

快速重传和快速恢复算法一般同时使用，快速恢复算法是认为，你还能收到 3 个重复 ACK 说明网络也不那么糟糕，所以没有必要像 `RTO` 超时那么强烈

正如前面所说，进入快速恢复之前，`cwnd` 和 `ssthresh` 已被更新了：

* `cwnd = cwnd/2` ，也就是设置为原来的一半
* `ssthresh = cwnd`

然后，进入快速恢复算法如下：

* 拥塞窗口 `cwnd = ssthresh + 3` （ 3 的意思是确认有 3 个数据包被收到了）
* 重传丢失的数据包
* 如果再收到重复的 ACK，那么 cwnd 增加 1
* 如果收到新数据的 ACK 后，设置 cwnd 为 sshthresh，接着进入了拥塞避免算法

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200816170116.png" style="zoom:67%;" />

也就是没有像「超时重传」一夜回到解放前，而是还在比较高的值，后续呈线性增长

### 网络层

#### IP 基本认识

网络层的主要作用是：**实现主机与主机之间的通信，也叫点对点通信**

> IP（网络层） 和 MAC（数据链路层）的区别和关系：
>
> IP 的作用是主机之间通信中的，而 MAC 的作用是实现 **直连** 的两个设备之间通信，而 IP 则负责在 **没有直连** 的两个网络之间进行通信传输
>
> <img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200813135119.png" style="zoom: 25%;" />
>
> 计算机网络中需要数据链路层和网络层这个分层才能实现向最终目标地址的通信
>
> 在网络数据包传输中，**源 IP 地址和目标 IP 地址在传输过程中是不会变化的，只有源 MAC 地址和目标 MAC 一直在变化**

#### IP 地址的基础知识

在 TCP/IP 网络通信时，为了保证能正常通信，每个设备都需要配置正确的 IP 地址，否则无法实现正常的通信

IP 地址（IPv4 地址）由 32 位正整数来表示，IP 地址在计算机是以二进制的方式处理的

##### IP 地址的分类

IP 地址分类成了 5 种类型，分别是 A 类、B 类、C 类、D 类、E 类

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200813140320.png" style="zoom: 50%;" />

##### 什么是 A，B，C 类地址

其中对于 A、B、C 类主要分为两个部分，分别是 **网络号** 和 **主机号**

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200813140620.png" style="zoom: 50%;" />

##### A，B，C 分类地址最大主机个数是如何计算的

最大主机个数，就是要看主机号的位数 n
$$
最大主机个数 = 2 ^ n - 2
$$
为什么要减 2 呢？

因为在 IP 地址中，有两个 IP 是特殊的，分别是**主机号全为 1** 和 **全为 0** 地址

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200813140925.png" style="zoom: 50%;" />

* 主机号全为 1 指定某个网络下的所有主机，用于广播
* 主机号全为 0 指定某个网络

##### 广播地址作用

广播地址用于在**同一个链路中相互连接的主机之间发送数据包**

**当主机号全为 1 时，就表示该网络的广播地址**

广播地址可以分为本地广播和直接广播：

* **在本网络内广播的叫做本地广播**
* **在不同网络之间的广播叫做直接广播**

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200813141549.png" style="zoom: 50%;" />

##### 什么是 D，E 类地址

D 类和 E 类地址是没有主机号的，所以不可用于主机 IP，D 类常被用于 **多播**，E 类是预留的分类，暂时未使用

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200813141815.png" style="zoom: 50%;" />

##### 多播地址的作用

多播用于**将包发送给特定组内的所有主机**

由于广播无法穿透路由，若想给其他网段发送同样的包，就可以使用可以穿透路由的多播（组播）

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200813165926.png" style="zoom: 50%;" />

多播使用的 D 类地址，其前四位是 `1110` 就表示是多播地址，而剩下的 28 位是多播的组编号

##### IP 分类的优点

不管是路由器还是主机解析到一个 IP 地址时候，我们判断其 IP 地址的首位是否为 0，为 0 则为 A 类地址，那么就能很快的找出网络地址和主机地址

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200813142335.png" style="zoom: 50%;" />

所以，这种分类地址的优点就是**简单明了、选路（基于网络地址）简单**

##### IP 分类的缺点

**缺点一**

**同一网络下没有地址层次，缺少地址的灵活性**

**缺点二**

**不能很好的与现实网络匹配**

* C 类地址能包含的最大主机数量实在太少了，只有 254 个，估计一个网吧都不够用
* B 类地址能包含的最大主机数量又太多了，6 万多台机器放在一个网络下面，一般的企业基本达不到这个规模，闲着的地址就是浪费

这两个缺点都可以在 CIDR 无分类地址解决

#### 无分类地址 CIDR

这种方式不再有分类地址的概念，32 比特的 IP 地址被划分为两部分，前面是 **网络号**，后面是 **主机号**

##### 怎么划分网络号和主机号

**表示形式 a.b.c.d/x**，其中 /x 表示前 x 位属于**网络号**，x 的范围是 0~32，这就使得 IP 地址更加具有灵活性

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200813143204.png" style="zoom:50%;" />

还有另一种划分网络号与主机号形式，那就是 **子网掩码**，掩码的意思是掩盖主机号，剩余的就是网络号

**将子网掩码和 IP 地址按位计算 AND，就可得到网络号**

##### 为什么要分离网络号和主机号

因为两台计算机要通讯，**首先要判断是否处于同一个广播域内，即网络地址是否相同**。如果网络地址相同，表明接受方在本网络上，那么可以把数据包直接发送到目标主机

路由器寻址工作中，也就是通过这样的方式来找到对应的网络号的，进而把数据包转发给对应的网络内

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200813150320.png" style="zoom:50%;" />

#### 怎么进行子网划分

可以通过子网掩码划分出网络号和主机号，那实际上子网掩码还有一个作用，那就是**划分子网**

**子网划分实际上是将主机地址划分为两个部分：子网网络地址和子网主机地址**

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200813150652.png" style="zoom:50%;" />

假设对 C 类地址进行子网划分，网络地址 192.168.1.0，使用子网掩码 255.255.255.192 对其进行子网划分

C 类地址中前 24 位 是网络号，最后 8 位是主机号，根据子网掩码可知**从 8 位主机号中借用 2 位作为子网号**

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200813151015.png" style="zoom:50%;" />

由于子网网络地址被划分成 2 位，那么子网地址就有 4 个，分别是 00、01、10、11

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200813151135.png" style="zoom: 50%;" />

划分后的 4 个子网如下表格：

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200813151318.png" style="zoom:50%;" />

#### IP 地址与路由控制

IP 地址的**网络地址**这一部分是用于进行路由控制

路由控制表中记录着网络地址与下一步应该发送至路由器的地址，在主机和路由器上都会有各自的路由器控制表

在发送 IP 包时，首先要确定 IP 包首部中的目标地址，再从路由控制表中找到与该地址具有**相同网络地址**的记录，根据该记录将 IP 包转发给相应的下一个路由器。如果路由控制表中存在多条相同网络地址的记录，就选择相同位数最多的网络地址，也就是**最长匹配**

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200813153258.png" style="zoom: 25%;" />

1. 主机 A 要发送一个 IP 包，其源地址是 `10.1.1.30` 和目标地址是 `10.1.2.10`， 由于没有在主机 A 的路由表找到与目标地址  `10.1.2.10` 相同的网络地址，于是把包被转发到默认路由（路由器 `1` ）
2. 路由器 `1` 收到 IP 包后，也在路由器 `1` 的路由表匹配与目标地址相同的网络地址记录，发现匹配到了，于是就把 IP 数据包转发到了 `10.1.0.2` 这台路由器 `2`
3. 路由器 `2` 收到后，同样对比自身的路由表，发现匹配到了，于是把 IP 包从路由器 `2` 的 `10.1.2.1` 这个接口出去，最终经过交换机把 IP 数据包转发到了目标主机

#### IP 分片与重组

**每种数据链路的最大传输单元 MTU 都是不相同的**

每种数据链路的 MTU 之所以不同，是因为每个不同类型的数据链路的使用目的不同。**使用目的不同，可承载的 MTU 也就不同**

那么**当 IP 数据包大小大于 MTU** 时， IP 数据包就会被**分片**

经过分片之后的 IP 数据报在被**重组**的时候，只能由**目标主机进行**，路由器是不会进行重组的

**在分片传输中，一旦某个分片丢失，则会造成整个 IP 数据报作废**，所以 **TCP 引入了 MSS** 也就是在 **TCP 层进行分片**不由 IP 层分片，那么对于 UDP 我们尽量不要发送一个大于 MTU 的数据报文

#### IP 协议相关技术

##### DNS 域名解析

DNS 可以将域名网址自动转换为具体的 IP 地址

**域名的层级关系**

DNS 中的域名都是用**句点**来分隔的，句点代表了不同层次之间的**界限**

在域名中，**越靠右**的位置表示其层级**越高**

所以域名的层级关系类似一个树状结构：

* 根域 DNS 服务器
* 顶级域 DNS 服务器（com）
* 权威 DNS 服务器（server.com）

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200813154725.png" style="zoom:50%;" />

根域的 DNS 服务器信息保存在互联网中所有的 DNS 服务器中。这样一来，任何 DNS 服务器就都可以找到并访问根域 DNS 服务器了

**域名解析的工作流程**

浏览器首先看一下自己的**缓存**里有没有，如果没有就向**操作系统的缓存**要，还没有就检查**本机域名解析文件** `hosts`，如果还是没有，就会 **DNS 服务器进行查询**，查询的过程如下：

1. 客户端首先会发出一个 DNS 请求，问 www.server.com 的 IP 是啥，并发给本地 DNS 服务器（也就是客户端的 TCP/IP 设置中填写的 DNS 服务器地址）
2. 本地域名服务器收到客户端的请求后，如果**缓存里的表格**能找到 www.server.com，则它直接返回 IP 地址。如果没有，本地 DNS 会**去问它的根域名服务器**：“老大， 能告诉我 www.server.com 的 IP 地址吗？”根域名服务器是最高层次的，它不直接用于域名解析，但能指明一条道路
3. 根 DNS 收到来自本地 DNS 的请求后，发现后置是 .com，说：“www.server.com 这个域名归 .com 区域管理”，我给你 .com 顶级域名服务器地址给你，你去问问它吧。”
4. 本地 DNS 收到**顶级域名服务器**的地址后，发起请求问“老二， 你能告诉我 www.server.com  的 IP 地址吗？”
5. 顶级域名服务器说：“我给你负责 www.server.com 区域的权威 DNS 服务器的地址，你去问它应该能问到”
6. 本地 DNS 于是转向问**权威 DNS 服务器**：“老三，www.server.com对应的IP是啥呀？” server.com 的权威 DNS 服务器，它是域名解析结果的原出处。为啥叫权威呢？就是我的域名我做主
7. 权威 DNS 服务器查询后将对应的 IP 地址 X.X.X.X 告诉本地 DNS
8. 本地 DNS 再将 IP 地址返回客户端，客户端和目标建立连接

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200813155046.png" style="zoom: 50%;" />

##### ARP

在传输一个 IP 数据报的时候，确定了源 IP 地址和目标 IP 地址后，就会通过主机「路由表」确定 IP 数据包下一跳。然而，网络层的下一层是数据链路层，所以我们还要知道「下一跳」的 MAC 地址

由于主机的路由表中可以找到下一条的 IP 地址，所以可以通过 **ARP 协议**，求得下一跳的 MAC 地址

**ARP 如何知道对方的 MAC 地址**

ARP 借助 **ARP 请求与 ARP 响应**两种类型的包确定 MAC 地址

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200813161159.png" style="zoom: 25%;" />

* 主机会通过**广播发送 ARP 请求**，这个包中包含了想要知道的 MAC 地址的主机 IP 地址
* 当同个链路中的所有设备收到 ARP 请求时，会去拆开 ARP 请求包里的内容，如果 ARP 请求包中的目标 IP 地址与自己的 IP 地址一致，那么这个设备就将自己的 MAC 地址塞入 **ARP 响应包**返回给主机

操作系统通常会把第一次通过 ARP 获取的 MAC 地址**缓存**起来，以便下次直接从缓存中找到对应 IP 地址的 MAC 地址

不过，MAC 地址的缓存是有一定**期限**的，超过这个期限，缓存的内容将被清除

##### RARP

ARP 协议是已知 IP 地址 求 MAC 地址，那 RARP 协议正好相反

它是**已知 MAC 地址求 IP 地址**

通常这需要架设一台 `RARP` 服务器，在这个服务器上注册设备的 MAC 地址以及 IP 地址，然后再将这个设备接入到网络，接着：

* 该设备会发送一条「我的 MAC 地址是XXXX，请告诉我，我的IP地址应该是什么」的请求信息
* RARP 服务器接到这个消息后返回「MAC地址为 XXXX 的设备，IP地址为 XXXX」的信息给这个设备

最后，设备就根据从 RARP 服务器所收到的应答信息设置自己的 IP 地址

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200813161450.png" style="zoom:25%;" />

##### DHCP

DHCP 在生活中我们是很常见的了，我们的电脑通常都是**通过 DHCP 动态获取 IP 地址**，大大省去了配 IP 信息繁琐的过程

接下来，我们来看看我们的电脑是如何通过 4 个步骤的过程，获取到 IP 的

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200813163550.png" style="zoom: 50%;" />

先说明一点，DHCP 客户端进程监听的是 68 端口号，DHCP 服务端进程监听的是 67 端口号

DHCP 交互的 4 个步骤：

* 客户端首先发起 **DHCP 发现报文（DHCP DISCOVER）** 的 IP 数据报，由于客户端没有 IP 地址，也不知道 DHCP 服务器的地址，所以使用的是 UDP 广播通信，其使用的广播目的地址是 255.255.255.255（端口 67）并且使用 0.0.0.0（端口 68）作为源 IP 地址。DHCP 客户端将该 IP 数据报传递给链路层，链路层然后将帧广播到所有的网络中设备
* DHCP 服务器收到 DHCP 发现报文时，用 **DHCP 提供报文（DHCP OFFER）**向客户端做出响应。该报文仍然使用 IP 广播地址 255.255.255.255，该报文信息携带服务器提供可租约的 IP 地址，子网掩码，默认网关，DNS 服务器以及 **IP 地址租用期**

* 客户端收到一个或多个服务器的 DHCP 提供报文后，从中选择一个服务器，并向选中的服务器发送 **DHCP 请求报文（DHCP REQUEST** 进行响应，回显配置的参数）
* 最后，服务端用 **DHCP ACK 报文**对 DHCP 请求报文进行响应，应答所要求的参数

一旦客户端收到 DHCP ACK 后，交互便完成了，并且客户端能够在租用期内使用 DHCP 服务器分配的 IP 地址

如果租约的 DHCP IP 地址快期后，客户端会向服务器发送 DHCP 请求报文：

* 服务器如果**同意**继续租用，则用 **DHCP ACK 报文**进行应答，客户端就会延长租期
* 服务器如果**不同意**继续租用，则用 **DHCP NACK 报文**，客户端就要停止使用租约的 IP 地址

可以发现，DHCP 交互中，**全程都是使用 UDP 广播通信**

用的是广播，那如果 DHCP 服务器和客户端不是在同一个局域网内，路由器又不会转发广播包，那不是每个网络都要配一个 DHCP 服务器？

所以，为了解决这一问题，就出现了 **DHCP 中继代理**

有了 DHCP 中继代理以后，**对不同网段的 IP 地址分配也可以由一个 DHCP 服务器统一进行管理**

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200813165224.png" style="zoom: 50%;" />

* DHCP 客户端会向 DHCP 中继代理发送 DHCP 请求包，而 DHCP 中继代理在收到这个广播包以后，再以**单播**的形式发给 DHCP 服务器
* 服务器端收到该包以后再向 DHCP 中继代理返回应答，并由 DHCP 中继代理将此包转发给 DHCP 客户端

因此，DHCP 服务器即使不在同一个链路上也可以实现统一分配和管理IP地址

##### NAT

**网络地址转换 NAT**，把私有 IP 地址转换成公有 IP 地址

由于绝大多数的网络应用都是使用传输层协议 TCP 或 UDP 来传输数据的。因此，可以把 **IP 地址 + 端口号一起进行转换**

这样，就用一个全球 IP 地址就可以了，这种转换技术就叫 **网络地址与端口转换 NAPT**

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200813170811.png" style="zoom: 67%;" />

图中有两个客户端 192.168.1.10 和 192.168.1.11 同时与服务器 183.232.231.172 进行通信，并且这两个客户端的本地端口都是 1025

此时，**两个私有 IP 地址都转换 IP 地址为公有地址 120.229.175.121，但是以不同的端口号作为区分**

于是，生成一个 NAPT 路由器的转换表，就可以正确地转换地址跟端口的组合，令客户端 A、B 能同时与服务器之间进行通信

##### ICMP

ICMP 全称是 **Internet Control Message Protocol**，也就是 **互联网控制报文协议**

> ICMP 功能

`ICMP` 主要的功能包括：**确认 IP 包是否成功送达目标地址**，**报告发送过程中 IP 包被废弃的原因**和**改善网络设置**等

在 `IP` 通信中如果某个 `IP` 包因为某种原因未能达到目标地址，那么这个具体的原因将**由 ICMP 负责通知**

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200813171620.png" style="zoom:50%;" />

如上图例子，主机 `A` 向主机 `B` 发送了数据包，由于某种原因，途中的路由器 `2` 未能发现主机 `B` 的存在，这时，路由器 `2` 就会向主机 `A` 发送一个 **`ICMP` 目标不可达数据包**，说明发往主机 `B` 的包未能成功。

ICMP 的这种通知消息会使用 `IP` 进行发送 。

因此，从路由器 `2` 返回的 ICMP 包会按照往常的路由控制先经过路由器 `1` 再转发给主机 `A` 。收到该 ICMP 包的主机 `A` 则**分解 ICMP 的首部和数据域**以后得知具体发生问题的原因。

> ICMP 包头格式

ICMP 报文是封装在 IP 包里面，它工作在网络层，是 IP 协议的助手

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200816173730.png" style="zoom: 67%;" />



**ICMP 包头的类型字段**

* 用于诊断的查询消息，也就是 **查询报文类型**
* 通知出错原因的错误消息，也就是 **差错报文类型**

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200813171900.png" style="zoom: 50%;" />

**查询报文类型：**

> 回送消息 —— 类型 `0` 和 `8`

**回送消息**用于进行通信的主机或路由器之间，判断所发送的数据包是否已经成功到达对端的一种消息，`ping`命令就是利用这个消息实现的

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200816174530.png" style="zoom: 67%;" />

<center><div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">ICMP 回送消息</div></center>

可以向对端主机发送 **回送请求** 的消息（ICMP Echo Request Message，类型 `8`），也可以接收对端主机发回来的 **回送应答** 消息（ICMP Echo Reply Message，类型 `0`）

![](https://raw.githubusercontent.com/whn961227/images/master/data/20200816174831.png)

<center><div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">ICMP 回送请求和回送应答报文</div></center>

相比原生的 ICMP，这里多了两个字段：

* **标识符**：用以区分是哪个应用程序发 ICMP 包，比如用进程 PID 作为标识符
* **序号**：序列号从 `0` 开始，每发送一次新的回送请求就会加 `1`，可以用来确认网络包是否有丢失

在**选项数据**中，`ping`还会存放发送请求的时间值，来计算往返时间，说明路程的长短

**差错报文类型：**

接下来，说明几个常用的 ICMP 差错报文的例子：

* 目标不可达消息 —— 类型 `3`
* 原点抑制消息 —— 类型 `4`
* 重定向消息 —— 类型 `5`
* 超时消息 —— 类型 `11`

> 目标不可达消息 —— 类型 `3`

IP 路由器无法将 IP 数据包发送到目标地址时，会给发送端主机返回一个**目标不可达**的 ICMP 消息，并在这个消息中显示不可达的具体原因，原因记录在 ICMP 包头的**代码**字段

由此，根据 ICMP 不可达的具体消息，发送端主机也就可以了解此次发送 **不可达的具体原因**

6 种常见的目标不可达类型的代码：

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200817092717.png" style="zoom: 33%;" />

**网络不可达：**

IP 地址是分为网络号和主机号，所以当路由器中的路由表匹配不到接收方 IP 的网络号，就通过 ICMP 协议以**网络不可达**（`Network Unreachable`）的原因告知主机

**主机不可达：**

当路由表中没有该主机的信息，或者该主机没有连接到网络，那么会通过 ICMP 协议以**主机不可达**（`Host Unreachable`）的原因告知主机

**协议不可达：**

当主机使用 TCP 协议访问对端主机时，能找到对端的主机了，可是对端主机的防火墙已经禁止 TCP 协议访问，那么会通过 ICMP 协议以**协议不可达**的原因告知主机

**端口不可达：**

当主机访问对端主机 8080 端口时，这次能找到对端主机了，防火墙也没有限制，可是发现对端主机没有进程监听 8080 端口，那么会通过 ICMP 协议以**端口不可达**的原因告知主机

**需要进行分片但设置了不分片：**

发送端主机发送 IP 数据报时，将 IP 首部的**分片禁止标志位**设置为`1`。根据这个标志位，途中的路由器遇到超过 MTU 大小的数据包时，不会进行分片，而是直接抛弃

随后，通过一个 ICMP 的不可达消息类型，**代码为 4** 的报文，告知发送端主机

> 原点抑制消息 —— 类型 `4`

> 重定向消息 —— 类型 `5`

如果路由器发现发送端主机使用了「不是最优」的路径发送数据，那么它会返回一个 ICMP **重定向消息**给这个主机

在这个消息中包含了**最合适的路由信息和源数据**。这主要发生在路由器持有更好的路由信息的情况下。路由器会通过这样的 ICMP 消息告知发送端，让它下次发给另外一个路由器

> 超时消息 —— 类型 `11`

IP 包中有一个字段叫做 `TTL（Time To Live，生命周期）`，它的**值随着每经过一次路由器就会减 1，直到减到 0 时 该 IP 包会被丢弃**

此时，IP 路由器将会发送一个 ICMP **超时消息**给发送端主机，并通知该包已被丢弃

设置 IP 包生存周期的主要目的，是为了在路由控制遇到问题发生循环状况时，避免 IP 包无休止地在网络上被转发

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200817095904.png" style="zoom:50%;" />

此外，有时可以用  TTL 控制包的到达范围，例如**设置一个较小的 TTL 值**

> ping —— 查询报文类型的使用

接下来，我们重点来看 `ping` 的**发送和接收过程**

同个子网下的主机 A 和 主机 B，主机 A 执行`ping` 主机 B 后，我们来看看其间发送了什么？

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200817101537.png" style="zoom: 50%;" />

ping 命令执行的时候，源主机首先会构建一个 **ICMP 回送请求消息**数据包

ICMP 数据包内包含多个字段，最重要的是两个：

* 第一个是**类型**，对于回送请求消息而言该字段为 `8`；
* 另外一个是**序号**，主要用于区分连续 ping 的时候发出的多个数据包

每发出一个请求数据包，序号会自动加 `1`。为了能够计算往返时间 RTT，它会在报文的数据部分插入发送时间

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200817102039.png" style="zoom: 50%;" />

<center><div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">主机 A 的 ICMP 回送请求报文</div></center>

然后，由 ICMP 协议将这个数据包连同地址 192.168.1.2 一起交给 IP 层。IP 层将以 192.168.1.2 作为**目的地址**，本机 IP 地址作为**源地址**，**协议**字段设置为 `1` 表示是 `ICMP` 协议，在加上一些其他控制信息，构建一个 `IP` 数据包

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200817102205.png" style="zoom:50%;" />

<center><div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">主机 A 的 IP 层数据包</div></center>

接下来，需要加入 `MAC` 头。如果在本地 ARP 映射表中查找出 IP 地址 192.168.1.2 所对应的 MAC 地址，则可以直接使用；如果没有，则需要发送 `ARP` 协议查询 MAC 地址，获得 MAC 地址后，由数据链路层构建一个数据帧，目的地址是 IP 层传过来的 MAC 地址，源地址则是本机的 MAC 地址；还要附加上一些控制信息，依据以太网的介质访问规则，将它们传送出去

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200817102327.png" style="zoom:50%;" />

主机 `B` 收到这个数据帧后，先检查它的目的 MAC 地址，并和本机的 MAC 地址对比，如符合，则接收，否则就丢弃

接收后检查该数据帧，将 IP 数据包从帧中提取出来，交给本机的 IP 层。同样，IP 层检查后，将有用的信息提取后交给 ICMP 协议

主机 `B` 会构建一个 **ICMP 回送响应消息**数据包，回送响应数据包的**类型**字段为 `0`，**序号**为接收到的请求数据包中的序号，然后再发送出去给主机 A

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200817102506.png" style="zoom:50%;" />

在规定的时候间内，源主机如果没有接到 ICMP 的应答包，则说明目标主机不可达；如果接收到了 ICMP 回送响应消息，则说明目标主机可达

此时，源主机会检查，用当前时刻减去该数据包最初从源主机上发出的时刻，就是 ICMP 数据包的时间延迟

针对上面发生的事情，总结成了如下图：

![](https://raw.githubusercontent.com/whn961227/images/master/data/20200817102633.png)

当然这只是最简单的，同一个局域网里面的情况。如果跨网段的话，还会涉及网关的转发、路由器的转发等等

但是对于 ICMP 的头来讲，是没什么影响的。会影响的是根据目标 IP 地址，选择路由的下一跳，还有每经过一个路由器到达一个新的局域网，需要换 MAC 头里面的 MAC 地址

说了这么多，可以看出 ping 这个程序是**使用了 ICMP 里面的 ECHO REQUEST（类型为 8 ） 和 ECHO REPLY （类型为 0）**



##### IGMP

在前面我们知道了组播地址，也就是 D 类地址，既然是组播，那就说明是只有一组的主机能收到数据包，不在一组的主机不能收到数组包，怎么管理是否是在一组呢？那么，就需要 `IGMP` 协议了

**IGMP 是因特网组管理协议，工作在主机（组播成员）和最后一跳路由之间**



### 当键入网址后，到网页显示，其间发生了什么

#### 孤单小弟 —— HTTP

> 浏览器做的第一步工作是解析 URL

首先浏览器做的第一步工作就是要对 `URL` 进行解析，从而生成发送给 Web 服务器的请求信息

让我们看看一条长长的 URL 里的各个元素的代表什么，见下图：

![](https://raw.githubusercontent.com/whn961227/images/master/data/20200817111037.png)

所以图中的长长的 URL 实际上是请求服务器里的文件资源

> 要是上图中的蓝色部分 URL 元素都省略了，哪应该是请求哪个文件呢？

当没有路径名时，就代表访问根目录下事先设置的**默认文件**，也就是 `/index.html` 或者 `/default.html` 这些文件，这样就不会发生混乱了

> 生成 HTTP 请求信息

对 `URL` 进行解析之后，浏览器确定了 Web 服务器和文件名，接下来就是根据这些信息来生成 HTTP 请求消息

![](https://raw.githubusercontent.com/whn961227/images/master/data/20200817111800.png)

> 一个孤单 HTTP 数据包表示：“我这么一个小小的数据包，没亲没友，直接发到浩瀚的网络，谁会知道我呢？谁能载我一层呢？谁能保护我呢？我的目的地在哪呢？”。充满各种疑问的它，没有停滞不前，依然踏上了征途！

#### 真实地址查询 —— DNS

通过浏览器解析 URL 并生成 HTTP 消息后，需要委托操作系统将消息发送给 `Web` 服务器

但在发送之前，还有一项工作需要完成，那就是**查询服务器域名对应的 IP 地址**，因为委托操作系统发送消息时，必须提供通信对象的 IP 地址

所以，有一种服务器就专门保存了 `Web` 服务器域名与 `IP` 的对应关系，它就是 `DNS` 服务器

DNS 域名解析的过程蛮有意思的，整个过程就和我们日常生活中找人问路的过程类似，**只指路不带路**

> 数据包表示：“DNS 老大哥厉害呀，找到了目的地了！我还是很迷茫呀，我要发出去，接下来我需要谁的帮助呢?”

#### 指南好帮手 —— 协议栈

通过 DNS 获取到 IP 后，就可以把 HTTP 的传输工作交给操作系统中的**协议栈**

协议栈的内部分为几个部分，分别承担不同的工作。上下关系是有一定的规则的，上面的部分会向下面的部分委托工作，下面的部分收到委托的工作并执行

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200817140956.png" style="zoom:50%;" />

应用程序（浏览器）通过调用 Socket 库，来委托协议栈工作。协议栈的上半部分有两块，分别是负责收发数据的 TCP 和 UDP 协议，它们两会接受应用层的委托执行收发数据的操作

协议栈的下面一半是用 IP 协议控制网络包收发操作，在互联网上传数据时，数据刽被切分成一块块的网络包，而将网络包发送给对方的操作就是由 IP 负责的

此外 IP 中还包括 `ICMP` 协议和 `ARP` 协议

* `ICMP` 用于告知网络包传送过程中产生的错误以及各种控制信息
* `ARP` 用于根据 IP 地址查询相应的以太网 MAC 地址

IP 下面的网卡驱动程序负责控制网卡硬件，而最下面的网卡则负责完成实际的收发操作，也就是对网线中的信号执行发送和接收操作

> 数据包看了这份指南表示：“原来我需要那么多大佬的协助啊，那我先去找找 TCP 大佬！”

#### 可靠传输 —— TCP

HTTP 是基于 TCP 协议传输的，所以在这我们先了解下 TCP 协议

> TCP 分割数据

如果 HTTP 请求消息比较长，超过了 MSS 的长度，这时 TCP 就需要把 HTTP 的数据拆解一块块的数据发送，而不是一次性发送所有数据

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200817141850.png" style="zoom:50%;" />

* MTU：一个网络包的最大长度，以太网中一般为 1500 字节
* MSS：除去 IP 和 TCP 头部之后，一个网络包所能容纳的 TCP 数据的最大长度

数据会被以 `MSS` 的长度为单位进行拆分，拆分出来的每一块数据都会被放进单独的网络包中。也就是在每个被拆分的数据加上 TCP 头信息，然后交给 IP 模块来发送数据

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200817142401.png" style="zoom:50%;" />

> TCP 报文生成

TCP 协议里面会有两个端口，一个是浏览器监听的端口（通常是随机生成的），一个是 Web 服务器监听的端口（HTTP 默认端口号是 `80`， HTTPS 默认端口号是 `443`）

在双方建立了连接后，TCP 报文中的数据部分就是存放 HTTP 头部 + 数据，组装好  TCP 报文之后，就需交给下面的网络层处理

![](https://raw.githubusercontent.com/whn961227/images/master/data/20200817142952.png)

> 此时，遇上了 TCP 的  数据包激动表示：“太好了，碰到了可靠传输的 TCP 传输，它给我加上 TCP 头部，我不在孤单了，安全感十足啊！有大佬可以保护我的可靠送达！但我应该往哪走呢？”

#### 远程定位 —— IP

TCP 模块在执行连接、收发、断开等各阶段操作时，都需要委托 IP 模块将数据封装成**网络包**发送给通信对象

> IP 包头格式

我们先看看 IP 报文头部的格式：

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200817143510.png" style="zoom:50%;" />

在 IP 协议里面需要有**源地址 IP** 和 **目标地址 IP**：

- 源地址IP，即是客户端输出的 IP 地址；
- 目标地址，即通过 DNS 域名解析得到的 Web 服务器 IP

因为 HTTP 是经过 TCP 传输的，所以在 IP 包头的**协议号**，要填写为 `06`（十六进制），表示协议为 TCP

> 假设客户端有多个网卡，就会有多个 IP 地址，那 IP 头部的源地址应该选择哪个 IP 呢？

当存在多个网卡时，在填写源地址 IP 时，就需要判断到底应该填写哪个地址。这个判断相当于在多块网卡中判断应该使用哪个一块网卡来发送包

这个时候就需要根据**路由表**规则，来判断哪一个网卡作为源地址 IP

在 Linux 操作系统，我们可以使用 `route -n` 命令查看当前系统的路由表

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200817144015.png" style="zoom:50%;" />

举个例子，根据上面的路由表，我们假设 Web 服务器的目标地址是 `192.168.10.200`

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200817144251.png" style="zoom:50%;" />

1. 首先先和第一条条目的子网掩码（`Genmask`）进行 **与运算**，得到结果为 `192.168.10.0`，但是第一个条目的 `Destination` 是 `192.168.3.0`，两者不一致所以匹配失败
2. 再与第二条目的子网掩码进行 **与运算**，得到的结果为 `192.168.10.0`，与第二条目的 `Destination 192.168.10.0` 匹配成功，所以将使用 `eth1` 网卡的 IP 地址作为 IP 包头的源地址

那么假设 Web 服务器的目标地址是 `10.100.20.100`，那么依然依照上面的路由表规则判断，判断后的结果是和第三条目匹配

第三条目比较特殊，它目标地址和子网掩码都是 `0.0.0.0`，这表示**默认网关**，如果其他所有条目都无法匹配，就会自动匹配这一行。并且后续就把包发给路由器，`Gateway` 即是路由器的 IP 地址

> IP 报文生成

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200817144618.png" style="zoom:50%;" />

> 此时，加上了 IP 头部的数据包表示 ：“有 IP 大佬给我指路了，感谢 IP 层给我加上了 IP 包头，让我有了远程定位的能力！不会害怕在浩瀚的互联网迷茫了！可是目的地好远啊，我下一站应该去哪呢？”

#### 两点传输 —— MAC

生成了 IP 头部之后，接下来网络包还需要在 IP 头部的前面加上 **MAC 头部**

> MAC 包头格式

MAC 头部是以太网使用的头部，它包含了接收方和发送方的 MAC 地址等信息

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200817144909.png" style="zoom:50%;" />

在 MAC 包头里需要**发送方 MAC 地址**和**接收方目标 MAC 地址**，用于**两点之间的传输**

一般在 TCP/IP 通信里，MAC 包头的**协议类型**只使用：

* 0800：IP 协议
* 0806：ARP 协议

> MAC 发送方和接收方如何确认？

**发送方**的 MAC 地址获取就比较简单了，MAC 地址是在网卡生产时写入到 ROM 里的，只要将这个值读取出来写入到 MAC 头部就可以了

**接收方**的 MAC 地址就有点复杂了，只要告诉以太网对方的 MAC 的地址，以太网就会帮我们把包发送过去，那么很显然这里应该填写对方的 MAC 地址

所以先得搞清楚应该把包发给谁，这个只要查一下**路由表**就知道了。在路由表中找到相匹配的条目，然后把包发给 `Gateway` 列中的 IP 地址就可以了

> 既然知道要发给谁，按如何获取对方的 MAC 地址呢？

此时就需要 `ARP` 协议帮我们找到路由器的 MAC 地址

> 好像每次都要广播获取，这不是很麻烦吗？

放心，在后续操作系统会把本次查询结果放到一块叫做 **ARP 缓存**的内存空间留着以后用，不过缓存的时间就几分钟

也就是说，在发包时：

- 先查询 ARP 缓存，如果其中已经保存了对方的 MAC 地址，就不需要发送 ARP 查询，直接使用 ARP 缓存中的地址
- 而当 ARP 缓存中不存在对方 MAC 地址时，则发送 ARP 广播查询

> 查看 ARP 缓存内容

在 Linux 系统中，我们可以使用 `arp -a` 命令来查看 ARP 缓存的内容

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200817145724.png" style="zoom:50%;" />

> MAC 报文生成

至此，网络包的报文如下图

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200817150012.png" style="zoom:50%;" />

#### 出口 —— 网卡

IP 生成的网络包只是存放在内存中的一串二进制数字信息，没有办法直接发送给对方。因此，我们需要将**数字信息转换为电信号**，才能在网线上传输，也就是说，这才是真正的数据发送过程

负责执行这一操作的是**网卡**，要控制网卡还需要靠**网卡驱动程序**

网卡驱动从 IP 模块获取到包之后，会将其**复制**到网卡内的缓存区中，接着会其**开头加上报头和起始帧分界符，在末尾加上用于检测错误的帧校验序列**

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200817150307.png" style="zoom:50%;" />

* 起始帧分界符是一个用来表示包起始位置的标记
* 末尾的 FCS（帧校验序列）用来检查包传输过程是否有损坏

最后网卡会将包转为电信号，通过网线发送出去

> 唉，真是不容易，发一个包，真是历经历经千辛万苦。致此，一个带有许多头部的数据终于踏上寻找目的地的征途了！

#### 送别者 —— 交换机

下面来看一下包是如何通过交换机的。交换机的设计是将网络包**原样**转发到目的地。交换机工作在 MAC 层，也称为**二层网络设备**

> 交换机的包接收操作

首先，电信号到达网线接口，交换机里的模块进行接收，接下来交换机里的模块将**电信号转换为数字信号**

然后通过包末尾的 `FCS` **校验**错误，如果没问题则**放到缓冲区**。这部分操作基本和计算机的网卡相同，但交换机的工作方式和网卡不同

计算机的网卡本身具有 MAC 地址，并通过核对收到的包的接收方 MAC 地址判断是不是发给自己的，如果不是发给自己的则丢弃；相对地，交换机的端口不核对接收方 MAC 地址，而是直接接收所有的包并存放到缓冲区中。因此，和网卡不同，**交换机的端口不具有 MAC 地址**

将包存入缓冲区后，接下来需要**查询**一下这个包的接收方 MAC 地址是否已经在 MAC 地址表中有记录了

交换机的 **MAC 地址表**主要包含两个信息：

* 一个是设备的 MAC 地址
* 另一个是该设备连接在交换机的哪个端口上

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200818092621.png" style="zoom:50%;" />

举个例子，如果收到的包的接收方 MAC 地址为 `00-02-B3-1C-9C-F9`，则与图中表中的第 3 行匹配，根据端口列的信息，可知这个地址位于 `3` 号端口上，然后就可以通过交换电路将包发送到相应的端口了

所以，**交换机根据 MAC 地址表查找 MAC 地址，然后将信号发送到相应的端口**

> 当 MAC 地址表找不到指定的 MAC 地址会怎么样？

地址表中找不到指定的 MAC 地址。这可能是因为**具有该地址的设备还没有向交换机发送过包**，或者**这个设备一段时间没有工作导致地址被从地址表中删除**了

这种情况下，交换机无法判断应该把包转发到哪个端口，只能将包转发到除了源端口之外的所有端口上，无论该设备连接在哪个端口上都能收到这个包

这样做不会产生什么问题，因为以太网的设计本来就是将包发送到整个网络的，然后**只有相应的接收者才能接收包，而其他设备则会忽略这个包**

有人会说：“这样做会发送多余的包，会不会造成网络拥塞呢？”

其实完全不用过于担心，因为发送了包之后目标设备会作出响应，只要返回了响应包，交换机就可以将它的地址写入 MAC 地址表，下次也就不需要把包发到所有端口了

局域网中每秒可以传输上千个包，多出一两个包并无大碍

此外，如果接收方 MAC 地址是一个**广播地址**，那么交换机会将包发送到除源端口之外的所有端口

以下两个属于广播地址：

* MAC 地址中的 `FF:FF:FF:FF:FF:FF`
* IP 地址中的 `255.255.255.255`

> 数据包通过交换机转发抵达了路由器，准备要离开土生土长的子网了。此时，数据包和交换机离别时说道：“感谢交换机兄弟，帮我转发到出境的大门，我要出远门啦！”

#### 出境大门 —— 路由器

> 路由器与交换机的区别

网络包经过交换机之后，现在到达了**路由器**，并在此被转发到下一个路由器或目标设备

这一步转发的工作原理和交换机类似，也是通过查表判断包转发的目标

不过在具体的操作过程上，路由器和交换机是有区别的

* 因为**路由器**是基于 IP 设计的，俗称**三层**网络设备，路由器的各个端口都具有 MAC 地址和 IP 地址
* 而**交换机**是基于以太网设计的，俗称**二层**网络设备，交换机的端口不具有 MAC 地址

> 路由器基本原理

路由器的端口具有 MAC 地址，因此它就能够成为以太网的发送方和接收方；同时还具有 IP 地址，从这个意义上来说，它和计算机的网卡是一样的

当转发包时，首先路由器端口会接收发给自己的以太网包，然后**路由表**查询转发目标，再由相应的端口作为发送方将以太网包发送出去

> 路由器的包接收操作

首先，电信号到达网线接口部分，路由器中的模块会将**电信号转成数字信号**，然后通过包末尾的 `FCS` 进行**错误校验**

如果没问题则检查 MAC 头部中的**接收方 MAC 地址**，看看是不是发给自己的包，如果是就放到接收缓冲区中，否则就丢弃这个包

总的来说，路由器的端口都具有 MAC 地址，只接收与自身地址匹配的包，遇到不匹配的包则直接丢弃

> 查询路由表确定输出端口

完成包接收操作之后，路由器就会**去掉**包开头的 MAC 头部

**MAC 头部的作用就是将包送达路由器**，其中的接收方 MAC 地址就是路由器端口的 MAC 地址。因此，当包到达路由器之后，MAC 头部的任务就完成了，于是 MAC 头部就会**被丢弃**

接下来，路由器会根据 MAC 头部后方的 `IP` 头部中的内容进行包的转发操作

转发操作分为几个阶段，首先是查询**路由表**判断转发目标

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200818104610.png" style="zoom:50%;" />

具体的工作流程根据上图，举个例子

假设地址为 `10.10.1.101` 的计算机要向地址为 `192.168.1.100` 的服务器发送一个包，，这个包先到达图中的路由器

判断转发目标的第一步，就是根据包的接收方 IP 地址**查询路由表**中的目标地址栏，以找到相匹配的记录

路由匹配和前面讲的一样，每个条目的子网掩码和 `192.168.1.100` IP 做 **& 与运算**后，得到的结果与对应条目的目标地址进行匹配，如果匹配就会作为候选转发目标，如果不匹配就继续与下个条目进行路由匹配

如第二条目的子网掩码 `255.255.255.0` 与 `192.168.1.100` IP 做 **& 与运算**后，得到结果是 `192.168.1.0` ，这与第二条目的目标地址 `192.168.1.0` 匹配，该第二条目记录就会被作为转发目标

实在找不到匹配路由时，就会选择**默认路由**，路由表中子网掩码为 `0.0.0.0` 的记录表示「默认路由」

> 路由器的发送操作

接下来就会进入包的**发送操作**

首先，我们需要根据**路由表的网关列**判断对方的地址

* 如果网关是一个 IP 地址，则这个IP 地址就是我们要转发到的目标地址，**还未抵达终点**，还需继续需要路由器转发
* 如果网关为空，则 IP 头部中的接收方 IP 地址就是要转发到的目标地址，也是就终于找到 IP 包头里的目标地址了，说明**已抵达终点**

知道对方的 IP 地址之后，接下来需要**通过 `ARP` 协议根据 IP 地址查询 MAC 地址**，并将查询的结果作为接收方 MAC 地址

**路由器也有 ARP 缓存**，因此首先会在 ARP 缓存中查询，如果找不到则发送 ARP 查询请求

接下来是发送方 MAC 地址字段，这里填写输出端口的 MAC 地址。还有一个以太类型字段，填写 `0080` （十六进制）表示 IP 协议

网络包完成后，接下来会将其转换成电信号并通过端口发送出去。这一步的工作过程和计算机也是相同的

发送出去的网络包会通过**交换机**到达下一个路由器。由于接收方 MAC 地址就是下一个路由器的地址，所以交换机会根据这一地址将包传输到下一个路由器

接下来，下一个路由器会将包转发给再下一个路由器，经过层层转发之后，网络包就到达了最终的目的地

不知你发现了没有，在网络包传输的过程中，**源 IP 和目标 IP 始终是不会变的，一直变化的是 MAC 地址，**因为需要 MAC 地址在以太网内进行**两个设备**之间的包传输

> 数据包通过多个路由器道友的帮助，在网络世界途径了很多路程，最终抵达了目的地的城门！城门值守的路由器，发现了这个小兄弟数据包原来是找城内的人，于是它就将数据包送进了城内，再经由城内的交换机帮助下，最终转发到了目的地了。数据包感慨万千的说道：“多谢这一路上，各路大侠的相助！”

#### 互相扒皮 —— 服务器与客户端

数据包抵达了服务器，服务器肯定高兴呀，正所谓有朋自远方来，不亦乐乎？

服务器高兴的不得了，于是开始扒数据包的皮！就好像你收到快递，能不兴奋吗？

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200818105722.png" style="zoom:50%;" />

数据包抵达服务器后，服务器会先扒开数据包的 MAC 头部，查看是否和服务器自己的 **MAC 地址**符合，符合就将包收起来

接着继续扒开数据包的 IP 头，发现 **IP 地址**符合，根据 IP 头中协议项，知道自己上层是 **TCP 协议**

于是，扒开 TCP 的头，里面有**序列号**，需要看一看这个序列包是不是我想要的，如果是就放入缓存中然后返回一个 ACK，如果不是就丢弃。TCP头部里面还有**端口号**， HTTP 的服务器正在监听这个端口号

于是，服务器自然就知道是 HTTP 进程想要这个包，于是就将包发给 HTTP 进程

服务器的 HTTP 进程看到，原来这个请求是要访问一个页面，于是就把这个网页封装在 **HTTP 响应报文**里

HTTP 响应报文也需要穿上 TCP、IP、MAC 头部，不过这次是源地址是服务器 IP 地址，目的地址是客户端 IP 地址

穿好头部衣服后，从网卡出去，交由交换机转发到出城的路由器，路由器就把响应数据包发到了下一个路由器，就这样跳啊跳

最后跳到了客户端的城门把手的路由器，路由器扒开 IP 头部发现是要找城内的人，于是把包发给了城内的交换机，再由交换机转发到客户端

客户端收到了服务器的响应数据包后，同样也非常的高兴，客户能拆快递了

于是，客户端开始扒皮，把收到的数据包的皮扒剩 HTTP 响应报文后，交给浏览器去渲染页面，一份特别的数据包快递，就这样显示出来了

最后，客户端要离开了，向服务器发起了 TCP 四次挥手，至此双方的连接就断开了

