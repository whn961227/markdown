## 网络

### 计算机网络体系结构

#### 五层协议

* **应用层：**为特定应用程序提供数据传输服务，例如 **HTTP**、**DNS** 、**SMTP**、**FTP**、**Telnet**等协议。数据单位为报文
* **传输层：**为主机中的**进程**提供通用数据传输服务。运输层包括两层协议：传输控制协议 **TCP**，提供面向连接、可靠的数据传输服务，数据单位为**报文段**；用户数据报协议 **UDP**，提供无连接、尽最大努力的数据传输服务，数据单位为**用户数据报**。TCP 主要提供完整性服务，UDP 主要提供及时性服务
* **网络层：**为**主机**提供数据传输服务。网络层把传输层传递下来的报文段和用户数据报封装成**分组**，包括 **IP**、**ARP** 协议
* **数据链路层：**主机之间可以有很多链路，链路层协议就是为同一链路的主机提供数据传输服务。数据链路层把网络层传下来的分组封装成**帧**，包括 **MAC** 协议
* **物理层：**考虑的是怎样在传输媒体上传输数据比特流，而不是指具体的传输媒体。物理层的作用是尽可能屏蔽传输媒体和通信手段的差异，使数据链路层感觉不到这些差异

#### OSI

* **表示层：**数据压缩、加密以及数据描述，这使得应用程序不必关心在各台主机中数据内部格式不同的问题
* **会话层：**建立及管理会话

#### TCP/IP

将数据链路层和物理层合并为**网络接口层**

TCP/IP 体系结构不严格遵循 OSI 分层概念，应用层可能会直接使用 IP 层或者网络接口层

#### 数据在各层之间的传递过程

在向下的过程中，需要**添加下层协议所需要的首部或者尾部**，而在向上的过程中不断**拆开首部和尾部**

**路由器**只有下面三层协议，因为路由器位于网络核心中，不需要为进程或者应用程序提供服务，因此也就不需要传输层和应用层

### HTTP（超文本传输协议）

#### 基础概念

**URI（Uniform Resource Identifier）：**统一资源标识符，包含 URL 和 URN

**URL（Uniform Resource Locator）：**统一资源定位符，https://www.google.com

**URN（Uniform Resource Name）：**统一资源名称，`urn:isbn:0451450523`

#### 特点

##### 优点

1. **简单**

   HTTP 基本的报文格式是 `header + body`，头部信息是 `key-value`简单文本的形式，易于理解

2. **灵活和易于扩展**

   HTTP 协议里的各类请求方法，URI/URL，状态码，头字段等每个组成要求都没有被固定死，都允许开发人员**自定义和扩充**

   同时 HTTP 由于是工作在应用层，则它**下层可以随意变化**，例如，HTTPS 就是在 HTTP 与 TCP 层之间增加了 SSL/TLS 安全传输层

3. **应用广泛和跨平台**

##### 缺点

1. **无状态**

   好处：因为服务器不会去记忆 HTTP 的状态，所以不需要额外的资源来记录状态信息，这能减轻服务器的负担，能够把更多的 CPU 和内存用来对外提供服务

   坏处：在完成关联性的操作时会非常麻烦，例如 `登录 -> 添加购物车 -> 下单 -> 结算 -> 支付`，这系列操作都要知道用户的身份才行，但服务器不知道这些请求是有关联的，每次都要问一遍身份信息

   解决：用 **Cookie** 技术

   > Cookie 通过在请求和响应报文中写入 Cookie 信息来控制客户端的状态
   >
   > <img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200812112651.png" style="zoom: 80%;" />

2. **明文传输**

3. **不安全**

   * 通信使用明文（不加密），内容可能会被**窃听**
   * 不验证通信方的身份，因此可能遭遇**伪装**
   * 无法证明报文的完整性，可能被**篡改**

   解决：用 HTTPS 的方式解决，通过引入  SSL/TLS 层

#### HTTP/1.1

##### 改进

1. **长连接**

   HTTP/1.0 性能上有一个很大的问题，每发起一个请求，都要新建一次 TCP 连接（三次握手），而且是串行请求，做了无谓的 TCP 连接建立和断开，增加了通信开销

   HTTP/1.1 提出了长连接的通信方式，也叫持久连接。这种方式的好处在于减少了 TCP 连接的重复建立和断开所造成的额外开销，减轻了服务器端的负载

   持久连接的特点是，主要任意一端没有明确提出断开连接，则保持 TCP 连接状态

   <img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200812114303.png"  />

2. **管道网络传输**

   HTTP/1.1 采用了长连接的方式，这使得管道网络传输成为了可能

   即可在同一个 TCP 连接里面，客户端可以发起多个请求，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间

   ![](https://raw.githubusercontent.com/whn961227/images/master/data/20200812114549.png)

##### 瓶颈

1. 请求/响应头部未经压缩就发送，首部信息越多延迟越大，只能压缩 Body 的部分
2. 发送冗长的首部。每次互相发送相同的首部造成的浪费较多
3. 服务器是按请求的顺序响应的，如果服务器响应慢，会导致客户端一直请求不到数据，也就是 **队头阻塞**
4. 没有请求优先级控制
5. 请求只能从客户端开始，服务器只能被动响应

#### HTTP/2

##### 优化

1. **头部压缩**

   HTTP/2 会 **压缩头** 如果同时发出多个请求，他们的头是一样的或是相似的，那么协议会帮你消除重复的部分

   > HPACK 算法：在客户端和服务端同时维护一张头信息表，所有字段都会存入这张表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就提高速度了

2. **二进制格式**

   HTTP/2 不再像 HTTP/1.1 里的纯文本形式的报文，而是全面采用了二进制格式，增加了数据传输的效率

   头信息和数据体都是二进制，并且统称为**帧**：**头信息帧和数据帧**

   <img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200812154830.png" style="zoom: 80%;" />

3. **数据流**

   HTTP/2 的数据包不是按顺序发送的，同一个连接里面连续的数据包，可能属于不同的回应。因此，必须对数据包做标记，指出它属于哪个回应

   **每个请求或回应的所有数据包，称为一个数据流（Stream）**

   每个数据流都标记着一个独一无二的编号，其中规定客户端发出的数据流编号为奇数，服务器发出的数据流编号为偶数

   客户端还可以指定**数据流的优先级**，优先级高的请求，服务器会先响应该请求

   <img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200812155222.png" style="zoom:67%;" />

4. **多路复用**

   HTTP/2 可以在**一个连接中并发多个请求或回应，而不用按顺序一一对应**

   移除了 HTTP/1.1 中的串行请求，不需要排队等待，也就不会出现 **队头阻塞** 的问题，**降低了延迟，大幅度提高了连接的利用率**

   <img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200812155514.png" style="zoom:67%;" />

5. **服务器推送**

   HTTP/2 在一定程度上改善了传统的 **请求-应答** 工作模式，服务端不再是被动的响应，也可以主动向客户端发送消息

##### 缺陷

HTTP/2 主要的问题在于：多个 HTTP 请求在复用一个 TCP 连接，下层的 TCP 协议是不知道有多少个 HTTP 请求的。所以一旦发生丢包现象，就会触发 TCP 的重传机制，这样在一个 TCP 连接中的**所有 HTTP 请求都必须等待这个丢了的包被重传回来**

* HTTP/1.1 中的管道传输中如果有一个请求阻塞了，那么队列后请求也统统被阻塞
* HTTP/2 多请求复用一个 TCP 连接，一旦发生丢包，就会阻塞住所有的 HTTP 请求

#### HTTP/3

这都是基于 TCP 传输层的问题，所以 **HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP**

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200812160235.png" style="zoom:67%;" />

UDP 发生是不管顺序，也不管丢包的，所以不会出现 HTTP/1.1 的 **队头阻塞** 和 HTTP/2 的一个丢包全部重传问题

UDP 是不可靠传输的，但是**基于 UDP 的 QUIC 协议**可以实现类似 TCP 的可靠性传输

* QUIC 有自己的一套机制可以保证可靠性传输。当某个流发生丢包时，只会阻塞该流，**其他流不会受到影响**

* TLS 升级成了 **1.3** 版本，头部压缩算法升级成了 **QPACK**

* HTTPS 要建立一个连接，要花费 6 次交互，先是建立三次握手，然后是 TLS/1.3 的三次握手。 QUIC 直接把以往的 TCP 和 TLS/1.3 的 6 次交互合并成了 3 次，减少了交互次数

  <img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200812160739.png" style="zoom: 80%;" />

#### HTTP 消息结构

##### 请求报文

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200811113929.png" style="zoom: 33%;" />

##### 响应报文

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200811114418.png" style="zoom: 33%;" />

##### 请求方法

###### HTTP 1.0

**GET：**获取资源

**HEAD：**获取报文首部，和 GET 方法类似，但是不返回报文实体主体部分

**POST：**传输实体主体

> **Get 和 Post 的区别：**
>
> Get 方法的含义是请求从服务器获取资源，这个资源可以是静态的文本 、页面、图片、视频等
>
> Post 方法向 URI 指定的资源提交数据，数据就放在报文的 body 里
>
> 安全和幂等：
>
> 『安全』：请求方法不会破坏服务器上的资源
>
> 『幂等』：多次执行相同的操作，结果都是相同的
>
> **GET 方法**是**安全且幂等**的，因为它是只读操作，无论操作多少次，服务器上的数据都是安全的，且每次的结果都是相同的
>
> **POST 方法**是新增或提交数据操作，会修改服务器上的资源，所以是**不安全**的，且多次提交数据会创建多个资源，所以**不是幂等**的

###### HTTP 1.1

**PUT：**上传文件

**PATCH：**对资源进行部分修改

**DELETE：**删除文件

**OPTIONS：**查询支持的方法

**CONNECT：**要求在与代理服务器通信时建立隧道

**TRACE：**追踪路径

##### 状态码

| 状态码 | 类别                             | 含义                       |
| ------ | -------------------------------- | -------------------------- |
| 1XX    | Informartional（信息性状态码）   | 接收的请求正在处理         |
| 2XX    | Success（成功状态码）            | 请求正常处理完毕           |
| 3XX    | Redirection（重定向状态码）      | 需要进行附加操作以完成请求 |
| 4XX    | Client Error（客户端错误状态码） | 服务器无法处理请求         |
| 5XX    | Server Error（服务器错误状态码） | 服务器处理请求出错         |

* 100 Continue：表明到目前为止都很正常，客户端可以继续发送请求或者忽略这个响应
* **200 OK：服务器响应成功，服务器找到了客户端请求的内容 ，并将内容发给了客户端**
* 204 No Content：请求已经成功处理，但是返回的响应报文不包含实体的主体部分。一般在只需要从客户端往服务器发送信息，而不需要返回数据时使用
* 206 Partial Content：表示客户端进行了范围请求，响应报文包含由 Content-Range 指定范围的实体内容
* **301 Moved Permanently：永久性重定向**
* **302 Found：临时性重定向**
* 303 See Other：和 302 有着相同的功能，但是 303 明确要求客户端应该采用 Get 方法获取资源
* **304 Not Modified：**如果请求报文首部包含一些条件，如果不满足条件，则服务器会返回 304 状态码
* 307 Temporary Redirect：临时性重定向，与 302 的含义类似，但是 307 要求浏览器不会把重定向请求的 POST 方法改成 GET 方法
* **400 Bad Request：请求报文中存在语法错误，无法被服务器解析**
* 401 Unauthorized：该状态码表示发送的请求需要有认证信息（BASIC 认证、DIGEST 认证）。如果之前已进行过一次请求，则表示用户认证失败
* **403 Forbidden：请求被拒绝**
* **404 Not Found：服务器上没有该资源，或者说是服务器上没有找到客户端请求的资源**
* **500 Internal Server Error：服务器正在执行请求时发生错误**
* **501 Not Implemented：**表示客户端请求的功能还不支持
* **502 Bad Gateway：**通常是服务器作为网关或代理时返回的错误码，表示服务器自身工作正常，访问后端服务器发生了错误
* 503 Service Unavailable：服务器暂时处于超负载或正在进行停机维护，现在无法处理请求

#### HTTP 工作原理

1. 客户端连接到 Web 服务器
2. 发送 HTTP 请求
3. 服务器接受请求并返回 HTTP 响应
4. 释放 TCP 连接
5. 客户端浏览器解析 HTML 内容



### HTTPS

#### 实现原理

HTTPS 是让 HTTP 的数据包通过 SSL/TLS 加密后传输。通过 SSL，HTTPS 具有了加密（防窃听）、认证（防伪装）和完整性保护（防篡改）

**SSL 安全套接层和 TLS 传输层安全协议**

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200812143738.png" style="zoom: 80%;" />

#### 工作流程

![](https://raw.githubusercontent.com/whn961227/images/master/data/20200812132016.png)

1. 用户在浏览器**发起 HTTPS 请求**（如 https://www.mogu.com/），默认使用服务器端的 **443 端口**进行连接
2. HTTPS 需要使用一套 **CA 数字证书**，证书内会附带一个**公钥 Pub**，而与之对应的**私钥 Private** 保留在服务器端不公开
3. 服务端收到请求，**返回配置好的包含公钥 Pub 的证书给客户端**
4. 客户端**收到证书**，**校验合法性**，主要包括是否在有效期内，证书的域名与请求的域名是否匹配，上一级证书是否有效（递归判断，直到判断到系统内置或浏览器配置好的根证书），如果不通过，则显示 HTTPS 警告信息，如果通过则继续
5. 客户端生成一个用于**对称加密的随机 key**，并用证书内的**公钥 Pub 进行加密**，发送给客户端
6. 服务端收到随机 Key 的密文，使用与公钥 Pub 配对的**私钥 Private 进行解密**，得到客户端真正想发送的**随机 Key**
7. 服务端使用客户端发送过来的**随机 key 对要传输的 HTTP 数据进行对称加密**，将密文返回给客户端
8. 客户端使用**随机 key 对称解密密文**，得到 HTTP 数据明文
9. 后续 HTTPS 请求**使用之前交换好的随机 key 进行对称加解密**

#### 对称机密和非对称加密

对称加密是指有一个密钥，用它可以对一段明文加密，加密之后也只能用这个密钥来解密得到明文；**速度快但是无法做到安全的密钥交换**

非对称加密有两个密钥，一个是公钥，一个是私钥，一般来说，公钥用来加密，这时密文只能用私钥才能解开；**解决了密钥交换的问题但是速度慢**

> 注意，严格来讲，私钥并不能用来加密，只能用作签名，这是由于密码学中生成公钥私钥时对不同变量的数学要求是不同的，因此公钥私钥抵抗攻击的能力也不同，在实际使用中不可互换

**为什么不采用两次非对称机密**

最主要的原因是**非对称加解密的耗时要远大于对称加解密**，对性能有很大损耗

#### CA 颁发机构

因为**客户端无法确认收到的公钥是不是真的是服务端发来的**，所以引入 CA

服务端在使用 HTTPS 之前，去经过认证的 CA 机构申请颁发一份**数字证书**，数字证书里包含有证书持有者、证书有效期、公钥等信息，服务端将证书发送给客户端，客户端校验证书身份和要访问的网站身份确实一致后再进行后续的加密操作

为了确认证书是否被篡改，需要采用防伪技术，**数字签名**

具体过程：

1. CA 机构拥有自己的一对公钥和私钥
2. CA 机构在颁发证书时对证书明文信息进行哈希
3. 将哈希值用**私钥进行加密**，得到数字签名

**明文数据和数字签名组成证书，传递给客户端**

1. 客户端得到证书，分解成明文部分 Text 和数字签名 Sig1
2. 用 CA 机构的**公钥进行解签**，得到 Sig2（由于 CA 机构是一种公信身份，因此在系统或浏览器中会内置 CA 机构的证书和公钥信息）
3. 用证书里声明的哈希算法对明文 Text 部分进行哈希得到 H
4. 当自己计算得到的哈希值 T 与**解签**后的 Sig2 **相等**，表示证书可信，没有被篡改

> 非对称加密的签名过程是，私钥将一段消息进行加签，然后将签名部分和消息本身一起发送给对方，收到消息后对签名部分利用公钥解签，如果解签出来的内容和消息本身一致，表明消息没有被篡改

#### HTTP 和 HTTPS 的区别

1. **HTTP** 是超文本传输协议，信息是**明文传输**，存在**安全风险**的问题。HTTPS 则解决 HTTP 不安全的缺陷，在 TCP 和 HTTP 网络层之间加入了 **SSL/TLS** 安全协议，使得报文能够**加密传输**
2. HTTP 连接建立相对简单，TCP **三次握手**之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 **SSL/TLS 的握手过程**，才可进入加密报文传输
3. HTTP 的端口号是 80，HTTPS 的端口号是 443
4. HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的

#### HTTPS 是如何解决 HTTP 的安全问题的（窃听、篡改、冒充）

* 混合加密的方式实现信息的**机密性**
* 摘要算法的方式来实现**完整性**
* 将服务器公钥放入到**数字证书**中，解决了冒充的风险

#### 总结

HTTPS 的出发点是解决 HTTP 明文传输时信息被篡改和监听的问题

* 为了兼顾性能和安全性，使用了非对称加密 + 对称加密的方案
* 为了保证公钥传输中不被篡改，又使用了非对称加密的数字签名功能，借助 CA 机构和系统根证书的机制保证了 HTTPS 证书的公信力

### 传输层

#### TCP 基本认识

##### 格式

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200812163324.png" style="zoom: 67%;" />

**序列号：**在建立连接时由计算机生成的随机数作为初始值，通过 SYN 包传给接收端主机，**每发送一次数据**，就**累加**一次该**数据字节数**的大小。**用来解决网络包乱序问题**

**确认应答号：**指下一次期望收到的数据的序列号，发送端收到这个确认应答后可以认为在这个序号以前的数据都已经被正常接收。**用来解决不丢包的问题**

**控制位：**

* ACK：该位为 1 时，确认应答的字段变为有效，TCP 规定除了最初建立连接时的 SYN 包之外该位必须设置为 1
* RST：该位为 1 时，表示 TCP 连接中出现异常必须强制断开连接
* SYN：该位为 1 时，表示希望建立连接，并在其序列号的字段进行序列号初始值的设定
* FIN：该位为 1 时，表示今后不会再有数据发送，希望断开连接。当通信结束希望断开连接时，通信双方的主机之间就可以互相交换 FIN 位置为 1 的 TCP 段

##### 为什么需要 TCP 协议

IP 层是不可靠的，它不保证网络包的交付，不保证网络包的按序交付，也不保证网络包中的数据的完整性

如果需要保障网路数据包的可靠性，那么就需要由上层（传输层）的 TCP 协议来负责

因为 TCP 是一个工作在**传输层**的可靠数据传输的服务，它能确保接收端接收的网络包是**无损坏，无间隔，非冗余和按序的**

##### 什么是 TCP

TCP 是**面向连接的**，**可靠的**，**基于字节流**的传输层通信协议

* 面向连接：一定是 **一对一** 才能连接，不能像 UDP 协议可以一个主机同时向多个主机发送消息，也就是一对多是无法做到的
* 可靠的：无论网络链路中出现了怎样的链路变化，TCP 都可以保证一个报文一定能够到达接收端
* 字节流：消息是没有边界的，所以无论消息有多大都可以进行传输。并且消息是**有序**的，当前一个消息没有接收到的时候，及时它先收到了后面的字节，也不能给应用层处理，同时对重复的报文会自动丢弃

##### 什么是 TCP 连接

用于保证可靠性和流量控制维护的某些状态信息，这些信息的组合，包括 **Socket**、**序列号**和**窗口大小**称为连接

* Socket：由 IP 地址和端口号组成
* 序列号：用来解决乱序问题
* 窗口大小：用来做流量控制

##### 如何唯一确定一个 TCP 连接

TCP 四元组可以唯一的确定一个连接

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200812171125.png" style="zoom: 50%;" />

源地址和目的地址的字段（32 位）是在 IP 头部中，作用是通过 IP 协议发送报文给对方主机

源端口和目的端口的字段（16  位）是在 TCP 头部中，作用是告诉 TCP 协议应该把报文发给哪个进程

#### UDP 基本认识

UDP 不提供复杂的控制机制，利用 IP 提供面向**无连接**的通信服务

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200812172211.png" style="zoom: 50%;" />

* 目标和源端口：告诉 UDP 协议应该把报文发给哪个进程
* 包长度：该字段保存了 UDP 首部的长度跟数据的长度之和
* 校验和：为了提供可靠的 UDP 首部和数据而设计

#### TCP 和 UDP 的区别

1. **连接**
   * TCP 是面向连接的传输层协议，传输数据前要先建立连接
   * UDP 是不需要连接，即刻传输数据
2. **服务对象**
   * TCP 是一对一的两点服务，即一条连接只有两个端点
   * UDP 支持一对一、一对多、多对多的交互通信
3. **可靠性**
   * TCP 是可靠交付数据的，数据可以无差错、不丢失、不重复、按需到达
   * UDP 是尽最大努力交付，不保证可靠交付数据
4. **拥塞控制、流量控制**
   * TCP 有拥塞控制和流量控制机制，保证数据传输的安全性
   * UDP 没有，即使网络非常拥堵，也不会影响 UDP 的发送速率
5. **首部开销**
   * TCP 首部长度较长，会有一定的开销，首部在没有使用**选项**字段时是 20 个字节，如果使用了选项字段则会变长
   * UDP 首部只有 8 个字节，并且是固定不变的，开销较小

#### TCP 和 UDP 应用场景

由于 TCP 是面向连接，能保证数据的可靠性交付，因此经常用于：

* FTP 文件传输
* HTTP/HTTPS

由于 UDP 面向无连接，它可以随时发送数据，再加上UDP 本身的处理既简单又高效，因此经常用于：

* 包总量较少的通信，如 DNS，SNMP 等
* 视频、音频等多媒体通信
* 广播通信

#### 为什么 UDP 头部没有 **首部长度** 字段，TCP 却有

TCP 有可变长的**选项**字段，而 UDP 头部长度是**不会变化**的，无需多一个字段去记录 UDP 的头部长度

#### 为什么 UDP 头部有 **包长度** 字段，TCP 却没有

TCP 计算负载数据长度：
$$
TCP数据的长度 = IP总长度 - IP首部长度 - TCP首部长度
$$
**因为为了网络设备硬件设计和处理方便，首部长度需要是 4 字节的整数倍**

如果去掉 UDP 包长度字段，那么 UDP 首部长度就不是 4 字节的整数倍了，所以为了补全 UDP 首部长度是 4 字节的整数倍，才补充了包长度字段

#### TCP 建立连接

TCP 是面向连接的协议，所以使用 TCP 前必须先建立连接，而**建立连接是通过三次握手进行的**

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200812205839.png" style="zoom:67%;" />

* 一开始，客户端和服务端都处于 CLOSED 状态，先是服务端主动监听某个端口，处于 LISTEN 状态

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200812210006.png" style="zoom: 67%;" />

* 客户端会随机初始化序号（client_isn），将此序号置于 TCP 首部的**序列号**字段中，同时把 **SYN** 标志位置位 **1**，表示 SYN 报文。接着把第一个 SYN 报文发送给服务端，表示向服务端发起连接，该报文不包含应用层数据，之后客户端处于 **SYN-SENT** 状态

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200812210522.png" style="zoom: 67%;" />

* 服务端收到客户端的 SYN 报文后，首先服务端也随机初始化自己的序号（server_isn），将此序号填入 TCP 首部的**序列号**字段中，其次把 TCP 首部的**确认应答号**字段填入 **client_isn+1**， 接着**把 SYN 和 ACK 标志位置为 1**，最后把该报文发给客户端，该报文也不包含应用层数据，之后服务端处于 **SYN-RCVD** 状态

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200812211111.png" style="zoom:67%;" />

* 客户端收到服务端报文后，还要向服务端回应最后一个应答报文，首先该应答报文 TCP 首部 **ACK 标志位置为 1**，其次**确认应答号**字段填入 **server_isn+1**，最后把报文发送给服务端，这次报文**可以携带客户到服务器的数据**，之后客户端处于 **ESTABLISHED** 状态
* 服务器收到客户端的应答报文后，也进入 **ESTABLISHED** 状态

从上面的过程可以发现**第三次握手是可以携带数据的，前两次握手是不可以携带数据的**

#### 如何在 linux 系统中查看 TCP 状态

通过 netstat -napt 命令查看

![](https://raw.githubusercontent.com/whn961227/images/master/data/20200812211544.png)

#### 为什么是三次握手，不是两次、四次

* 可以阻止历史重复连接的初始化（主要原因）
* 可以同步双方的初始序列号
* 可以避免资源浪费

**原因一：避免历史连接**

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200812212150.png" style="zoom: 50%;" />

客户端连续发送多次 SYN 建立连接的报文，在网络拥堵等情况下：

* 一个旧 SYN 报文比最新的 SYN 报文早到达了服务端
* 那么此时服务端就会回一个 **SYN+ACK** 报文给客户端
* 客户端收到后可以根据自身的上下文，判断这是一个历史连接（序列号过期或超时），那么客户端就会发送 **RST** 报文给服务端，表示终止这一次连接

如果是两次握手连接，就不能判断当前连接是否是历史连接，三次握手则可以在客户端（发送方）准备发送第三次报文时，客户端因有足够的上下文来判断当前连接是否是历史连接：

* 如果是历史连接（序列号过期或者超时），则第三次握手发送的报文是 **RST** 报文，以此中断历史连接
* 如果不是历史连接，则第三次发送的报文是 **ACK** 报文，通信双方就会成功建立连接

所以，TCP 使用三次握手建立连接的最主要原因是**防止历史连接初始化**

**原因二：同步双方初始序列号**

TCP 协议的通信双方，都必须维护一个 **序列号**，序列号是可靠传输的一个关键因素，它的作用：

* 接收方可以去除重复的数据
* 接收方可以根据数据包的序列号按序接收
* 可以标识发送出去的数据包中，哪些是已经被对方收到的

可见，序列号在 TCP 连接中占据着非常重要的作用，所以当客户端发送携带 **初始序列号** 的 **SYN** 报文的时候，需要服务端回一个 **ACK** 的应答报文，表示客户端的 **SYN** 报文已被服务端成功接收，那当服务端发送 **初始序列号** 给客户端的时候，依然也要得到客户端的应答回应，**这样一来一回，才能确保双方的初始序列号能被可靠的同步**

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200812213126.png" style="zoom:80%;" />

四次握手其实也能够可靠的同步双方的初始序列号，但由于第二步和第三步可以优化成一步，所以就成了三次握手

而两次握手只保证了一方的初始序列号能被对方成功接收，没办法保证双方的初始序列号都能被确认接收

**原因三：避免资源浪费**

如果只有两次握手，当客户端的 **SYN** 请求连接在网络中阻塞， 客户端没有接收到 **ACK** 报文，就会重新发送 **SYN**，由于没有第三次握手，服务器不清楚客户端是否收到了自己发送的建立连接的 **ACK** 确认信号，所以每收到一个 **SYN** 就只能先主动建立一个连接

如果客户端的 **SYN** 阻塞了，重复发送多次 **SYN** 报文，那么服务器在收到请求后就会**建立多个冗余的无效连接，造成不必要的资源浪费**

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200812213720.png" style="zoom: 50%;" />

**小结**

TCP 建立连接时，通过三次握手**能防止历史连接的建立，能减少双方不必要的资源开销，能帮助双方同步初始序列号**。序列号能够保证数据包不重复、不丢弃和按序传输

不使用 **两次握手** 和 **四次握手** 的原因：

* 两次握手：无法防止历史连接的建立，会造成双方资源的浪费，也无法可靠的同步双方序列号
* 四次握手：三次握手就已经理论上最少可靠建立连接，所以不需要使用更多的通信次数

#### 为什么客户端和服务端的初始序列号 ISN 是不相同的

因为网络中的报文**会延迟，会复制重发，也有可能丢失**，这样会造成的不同连接之间产生相互影响，所以为了避免互相影响，客户端和服务端的初始序列号是随机且不同的

#### 什么是 SYN 攻击，如何避免

**SYN 攻击**

我们都知道 TCP 连接建立是需要三次握手，假设攻击者短时间伪造不同 IP 地址的 `SYN` 报文，服务端每接收到一个 `SYN` 报文，就进入`SYN_RCVD` 状态，但服务端发送出去的 `ACK + SYN` 报文，无法得到未知 IP 主机的 `ACK` 应答，久而久之就会**占满服务端的 SYN 接收队列（未连接队列）**，使得服务器不能为正常用户服务。

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200812215248.png" style="zoom:80%;" />

**避免 SYN 攻击方式一**

通过修改 Linux 内核参数，**控制队列大小**和**当队列满时应做什么处理**

* 当网卡接收数据包的速度大于内核处理的速度时，会有一个队列保存这些数据包。控制该队列的最大值如下参数：

  ```
  net.core.netdev_max_backlog
  ```

* SYN_RCVD 状态连接的最大个数：

  ```
  net.ipv4.tcp_max_syn_backlog
  ```

* 超出处理能力时，对新的 SYN 直接返回 RST，丢弃连接：

  ```
  net.ipv4.tcp_abort_on_overflow
  ```

**避免 SYN 攻击方式二**

我们先来看下Linux 内核的 `SYN` （未完成连接建立）队列与 `Accept` （已完成连接建立）队列是如何工作的？

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200812215617.png" style="zoom: 50%;" />

正常流程：

* 当服务端接收到客户端的 SYN 报文时，会将其加入到内核的「 **SYN 队列**」；
* 接着发送 SYN + ACK 给客户端，等待客户端回应 ACK 报文；
* 服务端接收到 ACK 报文后，从「 SYN 队列」移除放入到「 **Accept 队列**」；
* 应用通过调用 `accept()` socket 接口，从「 Accept 队列」取出的连接。

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200812215741.png" style="zoom:50%;" />

应用程序过慢：

* 如果应用程序过慢时，就会导致「 Accept 队列」被占满

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200812215823.png" style="zoom:50%;" />

受到 SYN 攻击：

* 如果不断受到 SYN 攻击，就会导致「 SYN 队列」被占满。

tcp_syncookies 的方式可以应对 SYN 攻击的方法：

```
net.ipv4.tcp_syncookies = 1
```

<img src="https://raw.githubusercontent.com/whn961227/images/master/data/20200812215931.png" style="zoom:50%;" />

* 当 「 SYN 队列」满之后，后续服务器收到 SYN 包，不进入「 SYN 队列」；
* 计算出一个 `cookie` 值，再以 SYN + ACK 中的「**序列号**」返回客户端
* 服务端接收到客户端的应答报文时，服务器会**检查这个 ACK 包的合法性**。**如果合法，直接放入到「 Accept 队列」**
* 最后应用通过调用 `accept()` socket 接口，从「 Accept 队列」取出的连接。

